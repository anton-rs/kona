diff --git a/.github/workflows/cross_docker.yaml b/.github/workflows/cross_docker.yaml
index 59c56f0..7565c65 100644
--- a/.github/workflows/cross_docker.yaml
+++ b/.github/workflows/cross_docker.yaml
@@ -1,10 +1,7 @@
 name: Build and Publish Cross Images
-
 on: [workflow_dispatch, workflow_call]
-
 env:
   REGISTRY: ghcr.io
-
 jobs:
   build-pipelines:
     runs-on: ubuntu-latest
diff --git a/.github/workflows/trusted_sync_docker.yaml b/.github/workflows/trusted_sync_docker.yaml
deleted file mode 100644
index e14303e..0000000
--- a/.github/workflows/trusted_sync_docker.yaml
+++ /dev/null
@@ -1,38 +0,0 @@
-name: Publish Trusted Sync Binary Image
-
-on:
-  workflow_dispatch:
-
-env:
-  REGISTRY: ghcr.io
-
-jobs:
-  publish-ghcr:
-    runs-on: ubuntu-latest
-    permissions:
-      contents: read
-      packages: write
-    env:
-      IMAGE_NAME: ${{ github.repository }}/trusted-sync
-    steps:
-      - name: Checkout repository
-        uses: actions/checkout@v4
-      - name: Authenticate with container registry
-        uses: docker/login-action@v3
-        with:
-          registry: ${{ env.REGISTRY }}
-          username: ${{ github.actor }}
-          password: ${{ secrets.GITHUB_TOKEN }}
-      - name: Docker metadata
-        id: meta
-        uses: docker/metadata-action@v5
-        with:
-          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
-      - name: Build and Publish `trusted-sync`
-        uses: docker/build-push-action@v6
-        with:
-          file: examples/trusted-sync/Dockerfile
-          context: .
-          push: true
-          tags: ${{ steps.meta.outputs.tags }}
-          labels: ${{ steps.meta.outputs.labels }}
diff --git a/.gitignore b/.gitignore
index 67dad99..40224b7 100644
--- a/.gitignore
+++ b/.gitignore
@@ -3,6 +3,3 @@
 
 # Rust target
 target/
-
-# Environment Variables
-.env
diff --git a/Cargo.lock b/Cargo.lock
index e3211a5..e395a18 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -2,188 +2,6 @@
 # It is not intended for manual editing.
 version = 3
 
-[[package]]
-name = "actix-codec"
-version = "0.5.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5f7b0a21988c1bf877cf4759ef5ddaac04c1c9fe808c9142ecb78ba97d97a28a"
-dependencies = [
- "bitflags 2.5.0",
- "bytes",
- "futures-core",
- "futures-sink",
- "memchr",
- "pin-project-lite",
- "tokio",
- "tokio-util",
- "tracing",
-]
-
-[[package]]
-name = "actix-http"
-version = "3.8.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3ae682f693a9cd7b058f2b0b5d9a6d7728a8555779bedbbc35dd88528611d020"
-dependencies = [
- "actix-codec",
- "actix-rt",
- "actix-service",
- "actix-utils",
- "ahash",
- "base64",
- "bitflags 2.5.0",
- "brotli",
- "bytes",
- "bytestring",
- "derive_more",
- "encoding_rs",
- "flate2",
- "futures-core",
- "h2 0.3.26",
- "http 0.2.12",
- "httparse",
- "httpdate",
- "itoa",
- "language-tags",
- "local-channel",
- "mime",
- "percent-encoding",
- "pin-project-lite",
- "rand",
- "sha1",
- "smallvec",
- "tokio",
- "tokio-util",
- "tracing",
- "zstd",
-]
-
-[[package]]
-name = "actix-macros"
-version = "0.2.4"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e01ed3140b2f8d422c68afa1ed2e85d996ea619c988ac834d255db32138655cb"
-dependencies = [
- "quote",
- "syn 2.0.67",
-]
-
-[[package]]
-name = "actix-router"
-version = "0.5.3"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "13d324164c51f63867b57e73ba5936ea151b8a41a1d23d1031eeb9f70d0236f8"
-dependencies = [
- "bytestring",
- "cfg-if",
- "http 0.2.12",
- "regex",
- "regex-lite",
- "serde",
- "tracing",
-]
-
-[[package]]
-name = "actix-rt"
-version = "2.10.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "24eda4e2a6e042aa4e55ac438a2ae052d3b5da0ecf83d7411e1a368946925208"
-dependencies = [
- "futures-core",
- "tokio",
-]
-
-[[package]]
-name = "actix-server"
-version = "2.4.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b02303ce8d4e8be5b855af6cf3c3a08f3eff26880faad82bab679c22d3650cb5"
-dependencies = [
- "actix-rt",
- "actix-service",
- "actix-utils",
- "futures-core",
- "futures-util",
- "mio",
- "socket2",
- "tokio",
- "tracing",
-]
-
-[[package]]
-name = "actix-service"
-version = "2.0.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3b894941f818cfdc7ccc4b9e60fa7e53b5042a2e8567270f9147d5591893373a"
-dependencies = [
- "futures-core",
- "paste",
- "pin-project-lite",
-]
-
-[[package]]
-name = "actix-utils"
-version = "3.0.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "88a1dcdff1466e3c2488e1cb5c36a71822750ad43839937f85d2f4d9f8b705d8"
-dependencies = [
- "local-waker",
- "pin-project-lite",
-]
-
-[[package]]
-name = "actix-web"
-version = "4.8.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1988c02af8d2b718c05bc4aeb6a66395b7cdf32858c2c71131e5637a8c05a9ff"
-dependencies = [
- "actix-codec",
- "actix-http",
- "actix-macros",
- "actix-router",
- "actix-rt",
- "actix-server",
- "actix-service",
- "actix-utils",
- "actix-web-codegen",
- "ahash",
- "bytes",
- "bytestring",
- "cfg-if",
- "cookie",
- "derive_more",
- "encoding_rs",
- "futures-core",
- "futures-util",
- "itoa",
- "language-tags",
- "log",
- "mime",
- "once_cell",
- "pin-project-lite",
- "regex",
- "regex-lite",
- "serde",
- "serde_json",
- "serde_urlencoded",
- "smallvec",
- "socket2",
- "time",
- "url",
-]
-
-[[package]]
-name = "actix-web-codegen"
-version = "4.3.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "f591380e2e68490b5dfaf1dd1aa0ebe78d84ba7067078512b4ea6e4492d622b8"
-dependencies = [
- "actix-router",
- "proc-macro2",
- "quote",
- "syn 2.0.67",
-]
-
 [[package]]
 name = "addr2line"
 version = "0.22.0"
@@ -201,24 +19,25 @@ checksum = "f26201604c87b1e01bd3d98f8d5d9a8fcbb815e8cedb41ffccbeb4bf593a35fe"
 
 [[package]]
 name = "ahash"
-version = "0.8.11"
+version = "0.7.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e89da841a80418a9b391ebaea17f5c112ffaaa96f621d2c285b5174da76b9011"
+checksum = "891477e0c6a8957309ee5c45a6368af3ae14bb510732d2684ffa19af310920f9"
 dependencies = [
- "cfg-if",
  "getrandom",
  "once_cell",
  "version_check",
- "zerocopy",
 ]
 
 [[package]]
-name = "aho-corasick"
-version = "1.1.3"
+name = "ahash"
+version = "0.8.11"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "8e60d3430d3a69478ad0993f19238d2df97c507009a52b3c10addcd7f6bcb916"
+checksum = "e89da841a80418a9b391ebaea17f5c112ffaaa96f621d2c285b5174da76b9011"
 dependencies = [
- "memchr",
+ "cfg-if",
+ "once_cell",
+ "version_check",
+ "zerocopy",
 ]
 
 [[package]]
@@ -227,15 +46,6 @@ version = "2.0.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "cc7bb162ec39d46ab1ca8c77bf72e890535becd1751bb45f64c597edb4c8c6b3"
 
-[[package]]
-name = "alloc-stdlib"
-version = "0.2.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "94fb8275041c72129eb51b7d0322c29b8387a0386127718b096429201a5d6ece"
-dependencies = [
- "alloc-no-stdlib",
-]
-
 [[package]]
 name = "allocator-api2"
 version = "0.2.18"
@@ -591,7 +401,7 @@ dependencies = [
  "alloy-primitives",
  "alloy-rlp",
  "derive_more",
- "hashbrown",
+ "hashbrown 0.14.5",
  "nybbles",
  "smallvec",
  "tracing",
@@ -952,7 +762,6 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "74f7971dbd9326d58187408ab83117d8ac1bb9c17b085fdacd1cf2f598719b6b"
 dependencies = [
  "alloc-no-stdlib",
- "alloc-stdlib",
  "brotli-decompressor",
 ]
 
@@ -963,7 +772,6 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "9a45bd2e4095a8b518033b128020dd4a55aab1c0a381ba4404a472630f4bc362"
 dependencies = [
  "alloc-no-stdlib",
- "alloc-stdlib",
 ]
 
 [[package]]
@@ -978,6 +786,28 @@ version = "1.2.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "c3ac9f8b63eca6fd385229b3675f6cc0dc5c8a5c8a54a59d4f52ffd670d87b0c"
 
+[[package]]
+name = "bytecheck"
+version = "0.6.12"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "23cdc57ce23ac53c931e88a43d06d070a6fd142f2617be5855eb75efc9beb1c2"
+dependencies = [
+ "bytecheck_derive",
+ "ptr_meta",
+ "simdutf8",
+]
+
+[[package]]
+name = "bytecheck_derive"
+version = "0.6.12"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "3db406d29fbcd95542e92559bed4d8ad92636d1ca8b3b72ede10b4bcc010e659"
+dependencies = [
+ "proc-macro2",
+ "quote",
+ "syn 1.0.109",
+]
+
 [[package]]
 name = "byteorder"
 version = "1.5.0"
@@ -993,15 +823,6 @@ dependencies = [
  "serde",
 ]
 
-[[package]]
-name = "bytestring"
-version = "1.3.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "74d80203ea6b29df88012294f62733de21cfeab47f17b41af3a38bc30a03ee72"
-dependencies = [
- "bytes",
-]
-
 [[package]]
 name = "c-kzg"
 version = "1.0.2"
@@ -1021,11 +842,6 @@ name = "cc"
 version = "1.0.99"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "96c51067fd44124faa7f870b4b1c969379ad32b2ba805aa959430ceaa384f695"
-dependencies = [
- "jobserver",
- "libc",
- "once_cell",
-]
 
 [[package]]
 name = "cfg-if"
@@ -1115,17 +931,6 @@ version = "0.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6245d59a3e82a7fc217c5828a6692dbc6dfb63a0c8c90495621f7b9d79704a0e"
 
-[[package]]
-name = "cookie"
-version = "0.16.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e859cd57d0710d9e06c381b550c06e76992472a8c6d527aecd2fc673dcc231fb"
-dependencies = [
- "percent-encoding",
- "time",
- "version_check",
-]
-
 [[package]]
 name = "core-foundation"
 version = "0.9.4"
@@ -1151,15 +956,6 @@ dependencies = [
  "libc",
 ]
 
-[[package]]
-name = "crc32fast"
-version = "1.4.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a97769d94ddab943e4510d138150169a2758b5ef3eb191a9ee688de3e23ef7b3"
-dependencies = [
- "cfg-if",
-]
-
 [[package]]
 name = "crunchy"
 version = "0.2.2"
@@ -1195,7 +991,7 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "978747c1d849a7d2ee5e8adc0159961c48fb7e5db2f06af6723b80123bb53856"
 dependencies = [
  "cfg-if",
- "hashbrown",
+ "hashbrown 0.14.5",
  "lock_api",
  "once_cell",
  "parking_lot_core",
@@ -1211,15 +1007,6 @@ dependencies = [
  "zeroize",
 ]
 
-[[package]]
-name = "deranged"
-version = "0.3.11"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b42b6fa04a440b495c8b04d0e71b707c585f83cb9cb28cf8cd0d976c315e31b4"
-dependencies = [
- "powerfmt",
-]
-
 [[package]]
 name = "derivative"
 version = "2.2.0"
@@ -1391,16 +1178,6 @@ dependencies = [
  "static_assertions",
 ]
 
-[[package]]
-name = "flate2"
-version = "1.0.30"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5f54427cfd1c7829e2a139fcefea601bf088ebca651d2bf53ebc600eac295dae"
-dependencies = [
- "crc32fast",
- "miniz_oxide",
-]
-
 [[package]]
 name = "fnv"
 version = "1.0.7"
@@ -1579,16 +1356,16 @@ dependencies = [
 
 [[package]]
 name = "h2"
-version = "0.3.26"
+version = "0.4.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "81fe527a889e1532da5c525686d96d4c2e74cdd345badf8dfef9f6b39dd5f5e8"
+checksum = "fa82e28a107a8cc405f0839610bdc9b15f1e25ec7d696aa5cf173edbcb1486ab"
 dependencies = [
+ "atomic-waker",
  "bytes",
  "fnv",
  "futures-core",
  "futures-sink",
- "futures-util",
- "http 0.2.12",
+ "http",
  "indexmap",
  "slab",
  "tokio",
@@ -1597,22 +1374,12 @@ dependencies = [
 ]
 
 [[package]]
-name = "h2"
-version = "0.4.5"
+name = "hashbrown"
+version = "0.12.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "fa82e28a107a8cc405f0839610bdc9b15f1e25ec7d696aa5cf173edbcb1486ab"
+checksum = "8a9ee70c43aaf417c914396645a0fa852624801b24ebb7ae78fe8272889ac888"
 dependencies = [
- "atomic-waker",
- "bytes",
- "fnv",
- "futures-core",
- "futures-sink",
- "http 1.1.0",
- "indexmap",
- "slab",
- "tokio",
- "tokio-util",
- "tracing",
+ "ahash 0.7.8",
 ]
 
 [[package]]
@@ -1621,7 +1388,7 @@ version = "0.14.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "e5274423e17b7c9fc20b6e7e208532f9b19825d82dfd615708b70edd83df41f1"
 dependencies = [
- "ahash",
+ "ahash 0.8.11",
  "allocator-api2",
  "serde",
 ]
@@ -1662,17 +1429,6 @@ dependencies = [
  "digest 0.10.7",
 ]
 
-[[package]]
-name = "http"
-version = "0.2.12"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "601cbb57e577e2f5ef5be8e7b83f0f63994f25aa94d673e54a92d5c516d101f1"
-dependencies = [
- "bytes",
- "fnv",
- "itoa",
-]
-
 [[package]]
 name = "http"
 version = "1.1.0"
@@ -1691,7 +1447,7 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "1cac85db508abc24a2e48553ba12a996e87244a0395ce011e62b37158745d643"
 dependencies = [
  "bytes",
- "http 1.1.0",
+ "http",
 ]
 
 [[package]]
@@ -1702,7 +1458,7 @@ checksum = "793429d76616a256bcb62c2a2ec2bed781c8307e797e2598c50010f2bee2544f"
 dependencies = [
  "bytes",
  "futures-util",
- "http 1.1.0",
+ "http",
  "http-body",
  "pin-project-lite",
 ]
@@ -1713,12 +1469,6 @@ version = "1.9.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "0fcc0b4a115bf80b728eb8ea024ad5bd707b615bfed49e0665b6e0f86fd082d9"
 
-[[package]]
-name = "httpdate"
-version = "1.0.3"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "df3b46402a9d5adb4c86a0cf463f42e19994e3ee891101b1841f30a545cb49a9"
-
 [[package]]
 name = "hyper"
 version = "1.3.1"
@@ -1728,8 +1478,8 @@ dependencies = [
  "bytes",
  "futures-channel",
  "futures-util",
- "h2 0.4.5",
- "http 1.1.0",
+ "h2",
+ "http",
  "http-body",
  "httparse",
  "itoa",
@@ -1746,7 +1496,7 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "5ee4be2c948921a1a5320b629c4193916ed787a7f7f293fd3f7f5a6c9de74155"
 dependencies = [
  "futures-util",
- "http 1.1.0",
+ "http",
  "hyper",
  "hyper-util",
  "rustls",
@@ -1781,7 +1531,7 @@ dependencies = [
  "bytes",
  "futures-channel",
  "futures-util",
- "http 1.1.0",
+ "http",
  "http-body",
  "hyper",
  "pin-project-lite",
@@ -1829,7 +1579,7 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "168fb715dda47215e360912c096649d23d58bf392ac62f73919e831745e40f26"
 dependencies = [
  "equivalent",
- "hashbrown",
+ "hashbrown 0.14.5",
 ]
 
 [[package]]
@@ -1868,15 +1618,6 @@ version = "1.0.11"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "49f1f14873335454500d59611f1cf4a4b0f786f9ac11f4312a78e4cf2566695b"
 
-[[package]]
-name = "jobserver"
-version = "0.1.31"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "d2b099aaa34a9751c5bf0878add70444e1ed2dd73f347be99003d4577277de6e"
-dependencies = [
- "libc",
-]
-
 [[package]]
 name = "js-sys"
 version = "0.3.69"
@@ -1978,13 +1719,11 @@ dependencies = [
  "async-trait",
  "brotli",
  "c-kzg",
- "hashbrown",
+ "hashbrown 0.14.5",
  "kona-primitives",
- "lazy_static",
  "lru",
  "miniz_oxide",
  "op-alloy-consensus",
- "prometheus",
  "proptest",
  "reqwest",
  "revm",
@@ -2097,7 +1836,7 @@ dependencies = [
  "async-trait",
  "cfg-if",
  "kona-common",
- "serde",
+ "rkyv",
  "tempfile",
  "tokio",
  "tracing",
@@ -2119,12 +1858,6 @@ dependencies = [
  "superchain-primitives",
 ]
 
-[[package]]
-name = "language-tags"
-version = "0.3.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "d4345964bb142484797b161f473a503a434de77149dd8c7427788c6e13379388"
-
 [[package]]
 name = "lazy_static"
 version = "1.5.0"
@@ -2161,23 +1894,6 @@ version = "0.4.14"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "78b3ae25bc7c8c38cec158d1f2757ee79e9b3740fbc7ccf0e59e4b08d793fa89"
 
-[[package]]
-name = "local-channel"
-version = "0.1.5"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b6cbc85e69b8df4b8bb8b89ec634e7189099cea8927a276b7384ce5488e53ec8"
-dependencies = [
- "futures-core",
- "futures-sink",
- "local-waker",
-]
-
-[[package]]
-name = "local-waker"
-version = "0.1.4"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4d873d7c67ce09b42110d801813efbc9364414e356be9935700d368351657487"
-
 [[package]]
 name = "lock_api"
 version = "0.4.12"
@@ -2194,23 +1910,13 @@ version = "0.4.21"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "90ed8c1e510134f979dbc4f070f87d4313098b704861a105fe34231c70a3901c"
 
-[[package]]
-name = "loki-api"
-version = "0.1.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "674883a98273598ac3aad4301724c56734bea90574c5033af067e8f9fb5eb399"
-dependencies = [
- "prost",
- "prost-types",
-]
-
 [[package]]
 name = "lru"
 version = "0.12.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d3262e75e648fce39813cb56ac41f3c3e3f65217ebf3844d818d1f9398cfb0dc"
 dependencies = [
- "hashbrown",
+ "hashbrown 0.14.5",
 ]
 
 [[package]]
@@ -2251,7 +1957,6 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "a4a650543ca06a924e8b371db273b2756685faae30f8487da1b56505a8f78b0c"
 dependencies = [
  "libc",
- "log",
  "wasi",
  "windows-sys 0.48.0",
 ]
@@ -2327,12 +2032,6 @@ dependencies = [
  "num-traits",
 ]
 
-[[package]]
-name = "num-conv"
-version = "0.1.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "51d515d32fb182ee37cda2ccdcb92950d6a3c2893aa280e540671c2cd0f3b1d9"
-
 [[package]]
 name = "num-integer"
 version = "0.1.46"
@@ -2625,12 +2324,6 @@ version = "0.3.30"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d231b230927b5e4ad203db57bbcbee2802f6bce620b1e4a9024a07d94e2907ec"
 
-[[package]]
-name = "powerfmt"
-version = "0.2.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "439ee305def115ba05938db6eb1644ff94165c5ab5e9420d1c1bcedbba909391"
-
 [[package]]
 name = "ppv-lite86"
 version = "0.2.17"
@@ -2699,46 +2392,6 @@ dependencies = [
  "unicode-ident",
 ]
 
-[[package]]
-name = "procfs"
-version = "0.16.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "731e0d9356b0c25f16f33b5be79b1c57b562f141ebfcdb0ad8ac2c13a24293b4"
-dependencies = [
- "bitflags 2.5.0",
- "hex",
- "lazy_static",
- "procfs-core",
- "rustix",
-]
-
-[[package]]
-name = "procfs-core"
-version = "0.16.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "2d3554923a69f4ce04c4a754260c338f505ce22642d3830e049a399fc2059a29"
-dependencies = [
- "bitflags 2.5.0",
- "hex",
-]
-
-[[package]]
-name = "prometheus"
-version = "0.13.4"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3d33c28a30771f7f96db69893f78b857f7450d7e0237e9c8fc6427a81bae7ed1"
-dependencies = [
- "cfg-if",
- "fnv",
- "lazy_static",
- "libc",
- "memchr",
- "parking_lot",
- "procfs",
- "protobuf",
- "thiserror",
-]
-
 [[package]]
 name = "proptest"
 version = "1.5.0"
@@ -2760,43 +2413,25 @@ dependencies = [
 ]
 
 [[package]]
-name = "prost"
-version = "0.12.6"
+name = "ptr_meta"
+version = "0.1.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "deb1435c188b76130da55f17a466d252ff7b1418b2ad3e037d127b94e3411f29"
+checksum = "0738ccf7ea06b608c10564b31debd4f5bc5e197fc8bfe088f68ae5ce81e7a4f1"
 dependencies = [
- "bytes",
- "prost-derive",
+ "ptr_meta_derive",
 ]
 
 [[package]]
-name = "prost-derive"
-version = "0.12.6"
+name = "ptr_meta_derive"
+version = "0.1.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "81bddcdb20abf9501610992b6759a4c888aef7d1a7247ef75e2404275ac24af1"
+checksum = "16b845dbfca988fa33db069c0e230574d15a3088f147a87b64c7589eb662c9ac"
 dependencies = [
- "anyhow",
- "itertools 0.10.5",
  "proc-macro2",
  "quote",
- "syn 2.0.67",
-]
-
-[[package]]
-name = "prost-types"
-version = "0.12.6"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9091c90b0a32608e984ff2fa4091273cbdd755d54935c51d520887f4a1dbd5b0"
-dependencies = [
- "prost",
+ "syn 1.0.109",
 ]
 
-[[package]]
-name = "protobuf"
-version = "2.28.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "106dd99e98437432fed6519dedecfade6a06a73bb7b2a1e019fdd2bee5778d94"
-
 [[package]]
 name = "quick-error"
 version = "1.2.3"
@@ -2867,40 +2502,20 @@ dependencies = [
 ]
 
 [[package]]
-name = "regex"
-version = "1.10.5"
+name = "regex-syntax"
+version = "0.8.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b91213439dad192326a0d7c6ee3955910425f441d7038e0d6933b0aec5c4517f"
-dependencies = [
- "aho-corasick",
- "memchr",
- "regex-automata",
- "regex-syntax",
-]
+checksum = "7a66a03ae7c801facd77a29370b4faec201768915ac14a721ba36f20bc9c209b"
 
 [[package]]
-name = "regex-automata"
-version = "0.4.7"
+name = "rend"
+version = "0.4.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "38caf58cc5ef2fed281f89292ef23f6365465ed9a41b7a7754eb4e26496c92df"
+checksum = "71fe3824f5629716b1589be05dacd749f6aa084c87e00e016714a8cdfccc997c"
 dependencies = [
- "aho-corasick",
- "memchr",
- "regex-syntax",
+ "bytecheck",
 ]
 
-[[package]]
-name = "regex-lite"
-version = "0.1.6"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "53a49587ad06b26609c52e423de037e7f57f20d53535d66e08c695f347df952a"
-
-[[package]]
-name = "regex-syntax"
-version = "0.8.4"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "7a66a03ae7c801facd77a29370b4faec201768915ac14a721ba36f20bc9c209b"
-
 [[package]]
 name = "reqwest"
 version = "0.12.5"
@@ -2912,8 +2527,8 @@ dependencies = [
  "encoding_rs",
  "futures-core",
  "futures-util",
- "h2 0.4.5",
- "http 1.1.0",
+ "h2",
+ "http",
  "http-body",
  "http-body-util",
  "hyper",
@@ -2999,7 +2614,7 @@ dependencies = [
  "derive_more",
  "dyn-clone",
  "enumn",
- "hashbrown",
+ "hashbrown 0.14.5",
  "hex",
  "once_cell",
  "serde",
@@ -3039,6 +2654,35 @@ dependencies = [
  "digest 0.10.7",
 ]
 
+[[package]]
+name = "rkyv"
+version = "0.7.44"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "5cba464629b3394fc4dbc6f940ff8f5b4ff5c7aef40f29166fd4ad12acbc99c0"
+dependencies = [
+ "bitvec",
+ "bytecheck",
+ "bytes",
+ "hashbrown 0.12.3",
+ "ptr_meta",
+ "rend",
+ "rkyv_derive",
+ "seahash",
+ "tinyvec",
+ "uuid",
+]
+
+[[package]]
+name = "rkyv_derive"
+version = "0.7.44"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "a7dddfff8de25e6f62b9d64e6e432bf1c6736c57d20323e15ee10435fbda7c65"
+dependencies = [
+ "proc-macro2",
+ "quote",
+ "syn 1.0.109",
+]
+
 [[package]]
 name = "rlp"
 version = "0.5.2"
@@ -3201,6 +2845,12 @@ version = "1.2.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "94143f37725109f92c262ed2cf5e59bce7498c01bcc1502d7b9afe439a4e9f49"
 
+[[package]]
+name = "seahash"
+version = "4.1.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "1c107b6f4780854c8b126e228ea8869f4d7b71260f962fefb57b996b8959ba6b"
+
 [[package]]
 name = "sec1"
 version = "0.7.3"
@@ -3336,17 +2986,6 @@ dependencies = [
  "serde",
 ]
 
-[[package]]
-name = "sha1"
-version = "0.10.6"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e3bf829a2d51ab4a5ddf1352d8470c140cadc8301b2ae1789db023f01cedd6ba"
-dependencies = [
- "cfg-if",
- "cpufeatures",
- "digest 0.10.7",
-]
-
 [[package]]
 name = "sha2"
 version = "0.10.8"
@@ -3396,6 +3035,12 @@ dependencies = [
  "rand_core",
 ]
 
+[[package]]
+name = "simdutf8"
+version = "0.1.4"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "f27f6278552951f1f2b8cf9da965d10969b2efdea95a6ec47987ab46edfe263a"
+
 [[package]]
 name = "simple-revm"
 version = "0.1.0"
@@ -3423,12 +3068,6 @@ version = "1.13.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "3c5e1a9a646d36c3599cd173a41282daf47c44583ad367b8e6837255952e5c67"
 
-[[package]]
-name = "snap"
-version = "1.1.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1b6b67fb9a61334225b5b790716f609cd58395f895b3fe8b328786812a40bc3b"
-
 [[package]]
 name = "socket2"
 version = "0.5.7"
@@ -3532,7 +3171,7 @@ dependencies = [
  "alloy-primitives",
  "alloy-sol-types",
  "anyhow",
- "hashbrown",
+ "hashbrown 0.14.5",
  "serde",
  "serde_repr",
 ]
@@ -3655,37 +3294,6 @@ dependencies = [
  "num_cpus",
 ]
 
-[[package]]
-name = "time"
-version = "0.3.36"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5dfd88e563464686c916c7e46e623e520ddc6d79fa6641390f2e3fa86e83e885"
-dependencies = [
- "deranged",
- "itoa",
- "num-conv",
- "powerfmt",
- "serde",
- "time-core",
- "time-macros",
-]
-
-[[package]]
-name = "time-core"
-version = "0.1.2"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "ef927ca75afb808a4d64dd374f00a2adf8d0fcff8e7b184af886c3c87ec4a3f3"
-
-[[package]]
-name = "time-macros"
-version = "0.2.18"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3f252a68540fde3a3877aeea552b832b40ab9a69e318efd078774a01ddee1ccf"
-dependencies = [
- "num-conv",
- "time-core",
-]
-
 [[package]]
 name = "tiny-keccak"
 version = "2.0.2"
@@ -3864,17 +3472,6 @@ dependencies = [
  "valuable",
 ]
 
-[[package]]
-name = "tracing-log"
-version = "0.1.4"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "f751112709b4e791d8ce53e32c4ed2d353565a795ce84da2285393f41557bdf2"
-dependencies = [
- "log",
- "once_cell",
- "tracing-core",
-]
-
 [[package]]
 name = "tracing-log"
 version = "0.2.0"
@@ -3886,37 +3483,6 @@ dependencies = [
  "tracing-core",
 ]
 
-[[package]]
-name = "tracing-loki"
-version = "0.2.5"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "fea6023f9fe4b69267ccd3ed7d203d931c43c5f82dbaa0f07202bc17193a5f43"
-dependencies = [
- "loki-api",
- "reqwest",
- "serde",
- "serde_json",
- "snap",
- "tokio",
- "tokio-stream",
- "tracing",
- "tracing-core",
- "tracing-log 0.1.4",
- "tracing-serde",
- "tracing-subscriber",
- "url",
-]
-
-[[package]]
-name = "tracing-serde"
-version = "0.1.3"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "bc6b213177105856957181934e4920de57730fc69bf42c37ee5bb664d406d9e1"
-dependencies = [
- "serde",
- "tracing-core",
-]
-
 [[package]]
 name = "tracing-subscriber"
 version = "0.3.18"
@@ -3928,14 +3494,13 @@ dependencies = [
  "smallvec",
  "thread_local",
  "tracing-core",
- "tracing-log 0.2.0",
+ "tracing-log",
 ]
 
 [[package]]
 name = "trusted-sync"
 version = "0.1.0"
 dependencies = [
- "actix-web",
  "alloy-primitives",
  "alloy-provider",
  "alloy-rpc-types",
@@ -3943,13 +3508,10 @@ dependencies = [
  "anyhow",
  "clap",
  "kona-derive",
- "lazy_static",
- "prometheus",
  "reqwest",
  "serde",
  "tokio",
  "tracing",
- "tracing-loki",
  "tracing-subscriber",
 ]
 
@@ -4039,6 +3601,12 @@ version = "0.2.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "06abde3611657adf66d383f00b093d7faecc7fa57071cce2578660c9f1010821"
 
+[[package]]
+name = "uuid"
+version = "1.9.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "5de17fd2f7da591098415cff336e12965a28061ddace43b59cb3c430179c9439"
+
 [[package]]
 name = "valuable"
 version = "0.1.0"
@@ -4385,31 +3953,3 @@ dependencies = [
  "quote",
  "syn 2.0.67",
 ]
-
-[[package]]
-name = "zstd"
-version = "0.13.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "2d789b1514203a1120ad2429eae43a7bd32b90976a7bb8a05f7ec02fa88cc23a"
-dependencies = [
- "zstd-safe",
-]
-
-[[package]]
-name = "zstd-safe"
-version = "7.1.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1cd99b45c6bc03a018c8b8a86025678c87e55526064e38f9df301989dce7ec0a"
-dependencies = [
- "zstd-sys",
-]
-
-[[package]]
-name = "zstd-sys"
-version = "2.0.11+zstd.1.5.6"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "75652c55c0b6f3e6f12eb786fe1bc960396bf05a1eb3bf1f3691c3610ac2e6d4"
-dependencies = [
- "cc",
- "pkg-config",
-]
diff --git a/README.md b/README.md
index eb6b1b4..0643b67 100644
--- a/README.md
+++ b/README.md
@@ -9,9 +9,9 @@
 <p align="center">
   <a href="https://github.com/ethereum-optimism/kona/actions/workflows/rust_ci.yaml"><img src="https://github.com/ethereum-optimism/kona/actions/workflows/rust_ci.yaml/badge.svg?label=ci" alt="CI"></a>
   <a href="https://github.com/ethereum-optimism/kona/actions/workflows/fpvm_tests.yaml"><img src="https://github.com/ethereum-optimism/kona/actions/workflows/fpvm_tests.yaml/badge.svg?label=FPVM Tests" alt="FPVM Tests"></a>
-  <img src="https://img.shields.io/badge/License-MIT-green.svg?label=license&labelColor=2a2f35" alt="License">
-  <a href="https://ethereum-optimism.github.io/kona"><img src="https://img.shields.io/badge/Contributor%20Book-854a15?logo=mdBook&labelColor=2a2f35" alt="Book"></a>
-  <a href="https://github.com/ethereum-optimism/monorepo"><img src="https://img.shields.io/badge/OP%20Stack-monorepo-red?labelColor=2a2f35" alt="OP Stack"></a>
+  <img src="https://img.shields.io/badge/License-MIT-green.svg?label=license" alt="License">
+  <a href="https://ethereum-optimism.github.io/kona"><img src="https://img.shields.io/badge/Contributor%20Book-grey?logo=mdBook" alt="Book"></a>
+  <a href="https://github.com/ethereum-optimism/monorepo"><img src="https://img.shields.io/badge/OP%20Stack-monorepo-red" alt="OP Stack"></a>
 </p>
 
 <p align="center">
diff --git a/bin/client/src/comms/caching_oracle.rs b/bin/client/src/comms/caching_oracle.rs
index ab3d84d..8eac467 100644
--- a/bin/client/src/comms/caching_oracle.rs
+++ b/bin/client/src/comms/caching_oracle.rs
@@ -3,12 +3,12 @@
 //!
 //! [OracleReader]: kona_preimage::OracleReader
 
-use crate::ORACLE_READER;
+use crate::{HINT_WRITER, ORACLE_READER};
 use alloc::{boxed::Box, sync::Arc, vec::Vec};
 use anyhow::Result;
 use async_trait::async_trait;
 use core::num::NonZeroUsize;
-use kona_preimage::{PreimageKey, PreimageOracleClient};
+use kona_preimage::{HintWriterClient, PreimageKey, PreimageOracleClient};
 use lru::LruCache;
 use spin::Mutex;
 
@@ -63,3 +63,10 @@ impl PreimageOracleClient for CachingOracle {
         }
     }
 }
+
+#[async_trait]
+impl HintWriterClient for CachingOracle {
+    async fn write(&self, hint: &str) -> Result<()> {
+        HINT_WRITER.write(hint).await
+    }
+}
diff --git a/bin/client/src/kona.rs b/bin/client/src/kona.rs
index 7d81deb..8ddc924 100644
--- a/bin/client/src/kona.rs
+++ b/bin/client/src/kona.rs
@@ -9,7 +9,7 @@ use alloc::sync::Arc;
 use alloy_consensus::Header;
 use kona_client::{
     l1::{DerivationDriver, OracleBlobProvider, OracleL1ChainProvider},
-    l2::{OracleL2ChainProvider, TrieDBHintWriter},
+    l2::OracleL2ChainProvider,
     BootInfo, CachingOracle,
 };
 use kona_common_proc::client_entry;
@@ -60,8 +60,8 @@ fn main() -> Result<()> {
         let mut executor = StatelessL2BlockExecutor::new(
             &boot.rollup_config,
             driver.take_l2_safe_head_header(),
+            l2_provider.clone(),
             l2_provider,
-            TrieDBHintWriter,
         );
         let Header { number, .. } = *executor.execute_payload(attributes)?;
         let output_root = executor.compute_output_root()?;
diff --git a/bin/client/src/l1/blob_provider.rs b/bin/client/src/l1/blob_provider.rs
index 01b7375..265fa33 100644
--- a/bin/client/src/l1/blob_provider.rs
+++ b/bin/client/src/l1/blob_provider.rs
@@ -1,6 +1,6 @@
 //! Contains the concrete implementation of the [BlobProvider] trait for the client program.
 
-use crate::{CachingOracle, HintType, HINT_WRITER};
+use crate::HintType;
 use alloc::{boxed::Box, sync::Arc, vec::Vec};
 use alloy_consensus::Blob;
 use alloy_eips::eip4844::FIELD_ELEMENTS_PER_BLOB;
@@ -10,18 +10,18 @@ use kona_derive::{
     traits::BlobProvider,
     types::{BlobProviderError, IndexedBlobHash},
 };
-use kona_preimage::{HintWriterClient, PreimageKey, PreimageKeyType, PreimageOracleClient};
+use kona_preimage::{CommsClient, PreimageKey, PreimageKeyType};
 use kona_primitives::BlockInfo;
 
 /// An oracle-backed blob provider.
 #[derive(Debug, Clone)]
-pub struct OracleBlobProvider {
-    oracle: Arc<CachingOracle>,
+pub struct OracleBlobProvider<T: CommsClient> {
+    oracle: Arc<T>,
 }
 
-impl OracleBlobProvider {
+impl<T: CommsClient> OracleBlobProvider<T> {
     /// Constructs a new `OracleBlobProvider`.
-    pub fn new(oracle: Arc<CachingOracle>) -> Self {
+    pub fn new(oracle: Arc<T>) -> Self {
         Self { oracle }
     }
 
@@ -45,7 +45,7 @@ impl OracleBlobProvider {
         blob_req_meta[40..48].copy_from_slice(block_ref.timestamp.to_be_bytes().as_ref());
 
         // Send a hint for the blob commitment and field elements.
-        HINT_WRITER.write(&HintType::L1Blob.encode_with(&[blob_req_meta.as_ref()])).await?;
+        self.oracle.write(&HintType::L1Blob.encode_with(&[blob_req_meta.as_ref()])).await?;
 
         // Fetch the blob commitment.
         let mut commitment = [0u8; 48];
@@ -77,7 +77,7 @@ impl OracleBlobProvider {
 }
 
 #[async_trait]
-impl BlobProvider for OracleBlobProvider {
+impl<T: CommsClient + Sync + Send> BlobProvider for OracleBlobProvider<T> {
     async fn get_blobs(
         &mut self,
         block_ref: &BlockInfo,
diff --git a/bin/client/src/l1/chain_provider.rs b/bin/client/src/l1/chain_provider.rs
index c6725c9..940f905 100644
--- a/bin/client/src/l1/chain_provider.rs
+++ b/bin/client/src/l1/chain_provider.rs
@@ -1,6 +1,6 @@
 //! Contains the concrete implementation of the [ChainProvider] trait for the client program.
 
-use crate::{BootInfo, CachingOracle, HintType, HINT_WRITER};
+use crate::{BootInfo, HintType};
 use alloc::{boxed::Box, sync::Arc, vec::Vec};
 use alloy_consensus::{Header, Receipt, ReceiptEnvelope, TxEnvelope};
 use alloy_eips::eip2718::Decodable2718;
@@ -10,30 +10,30 @@ use anyhow::{anyhow, Result};
 use async_trait::async_trait;
 use kona_derive::traits::ChainProvider;
 use kona_mpt::{OrderedListWalker, TrieDBFetcher};
-use kona_preimage::{HintWriterClient, PreimageKey, PreimageKeyType, PreimageOracleClient};
+use kona_preimage::{CommsClient, PreimageKey, PreimageKeyType};
 use kona_primitives::BlockInfo;
 
 /// The oracle-backed L1 chain provider for the client program.
 #[derive(Debug, Clone)]
-pub struct OracleL1ChainProvider {
+pub struct OracleL1ChainProvider<T: CommsClient> {
     /// The boot information
     boot_info: Arc<BootInfo>,
     /// The preimage oracle client.
-    oracle: Arc<CachingOracle>,
+    pub oracle: Arc<T>,
 }
 
-impl OracleL1ChainProvider {
+impl<T: CommsClient> OracleL1ChainProvider<T> {
     /// Creates a new [OracleL1ChainProvider] with the given boot information and oracle client.
-    pub fn new(boot_info: Arc<BootInfo>, oracle: Arc<CachingOracle>) -> Self {
+    pub fn new(boot_info: Arc<BootInfo>, oracle: Arc<T>) -> Self {
         Self { boot_info, oracle }
     }
 }
 
 #[async_trait]
-impl ChainProvider for OracleL1ChainProvider {
+impl<T: CommsClient + Sync + Send> ChainProvider for OracleL1ChainProvider<T> {
     async fn header_by_hash(&mut self, hash: B256) -> Result<Header> {
         // Send a hint for the block header.
-        HINT_WRITER.write(&HintType::L1BlockHeader.encode_with(&[hash.as_ref()])).await?;
+        self.oracle.write(&HintType::L1BlockHeader.encode_with(&[hash.as_ref()])).await?;
 
         // Fetch the header RLP from the oracle.
         let header_rlp =
@@ -72,7 +72,7 @@ impl ChainProvider for OracleL1ChainProvider {
 
         // Send a hint for the block's receipts, and walk through the receipts trie in the header to
         // verify them.
-        HINT_WRITER.write(&HintType::L1Receipts.encode_with(&[hash.as_ref()])).await?;
+        self.oracle.write(&HintType::L1Receipts.encode_with(&[hash.as_ref()])).await?;
         let trie_walker = OrderedListWalker::try_new_hydrated(header.receipts_root, self)?;
 
         // Decode the receipts within the transactions trie.
@@ -103,7 +103,7 @@ impl ChainProvider for OracleL1ChainProvider {
 
         // Send a hint for the block's transactions, and walk through the transactions trie in the
         // header to verify them.
-        HINT_WRITER.write(&HintType::L1Transactions.encode_with(&[hash.as_ref()])).await?;
+        self.oracle.write(&HintType::L1Transactions.encode_with(&[hash.as_ref()])).await?;
         let trie_walker = OrderedListWalker::try_new_hydrated(header.transactions_root, self)?;
 
         // Decode the transactions within the transactions trie.
@@ -119,7 +119,7 @@ impl ChainProvider for OracleL1ChainProvider {
     }
 }
 
-impl TrieDBFetcher for OracleL1ChainProvider {
+impl<T: CommsClient> TrieDBFetcher for OracleL1ChainProvider<T> {
     fn trie_node_preimage(&self, key: B256) -> Result<Bytes> {
         // On L1, trie node preimages are stored as keccak preimage types in the oracle. We assume
         // that a hint for these preimages has already been sent, prior to this call.
diff --git a/bin/client/src/l1/driver.rs b/bin/client/src/l1/driver.rs
index dd8506a..df60d39 100644
--- a/bin/client/src/l1/driver.rs
+++ b/bin/client/src/l1/driver.rs
@@ -4,7 +4,7 @@
 //! [L2PayloadAttributes]: kona_derive::types::L2PayloadAttributes
 
 use super::{OracleBlobProvider, OracleL1ChainProvider};
-use crate::{l2::OracleL2ChainProvider, BootInfo, CachingOracle, HintType, HINT_WRITER};
+use crate::{l2::OracleL2ChainProvider, BootInfo, HintType};
 use alloc::sync::Arc;
 use alloy_consensus::{Header, Sealed};
 use anyhow::{anyhow, Result};
@@ -19,31 +19,32 @@ use kona_derive::{
     traits::{ChainProvider, L2ChainProvider},
 };
 use kona_mpt::TrieDBFetcher;
-use kona_preimage::{HintWriterClient, PreimageKey, PreimageKeyType, PreimageOracleClient};
+use kona_preimage::{CommsClient, PreimageKey, PreimageKeyType};
 use kona_primitives::{BlockInfo, L2AttributesWithParent, L2BlockInfo};
 use tracing::{info, warn};
 
 /// An oracle-backed derivation pipeline.
-pub type OraclePipeline =
-    DerivationPipeline<OracleAttributesQueue<OracleDataProvider>, OracleL2ChainProvider>;
+pub type OraclePipeline<O> =
+    DerivationPipeline<OracleAttributesQueue<OracleDataProvider<O>, O>, OracleL2ChainProvider<O>>;
 
 /// An oracle-backed Ethereum data source.
-pub type OracleDataProvider = EthereumDataSource<OracleL1ChainProvider, OracleBlobProvider>;
+pub type OracleDataProvider<O> =
+    EthereumDataSource<OracleL1ChainProvider<O>, OracleBlobProvider<O>>;
 
 /// An oracle-backed payload attributes builder for the `AttributesQueue` stage of the derivation
 /// pipeline.
-pub type OracleAttributesBuilder =
-    StatefulAttributesBuilder<OracleL1ChainProvider, OracleL2ChainProvider>;
+pub type OracleAttributesBuilder<O> =
+    StatefulAttributesBuilder<OracleL1ChainProvider<O>, OracleL2ChainProvider<O>>;
 
 /// An oracle-backed attributes queue for the derivation pipeline.
-pub type OracleAttributesQueue<DAP> = AttributesQueue<
+pub type OracleAttributesQueue<DAP, O> = AttributesQueue<
     BatchQueue<
         ChannelReader<
-            ChannelBank<FrameQueue<L1Retrieval<DAP, L1Traversal<OracleL1ChainProvider>>>>,
+            ChannelBank<FrameQueue<L1Retrieval<DAP, L1Traversal<OracleL1ChainProvider<O>>>>>,
         >,
-        OracleL2ChainProvider,
+        OracleL2ChainProvider<O>,
     >,
-    OracleAttributesBuilder,
+    OracleAttributesBuilder<O>,
 >;
 
 /// The [DerivationDriver] struct is responsible for handling the [L2PayloadAttributes] derivation
@@ -54,16 +55,16 @@ pub type OracleAttributesQueue<DAP> = AttributesQueue<
 ///
 /// [L2PayloadAttributes]: kona_derive::types::L2PayloadAttributes
 #[derive(Debug)]
-pub struct DerivationDriver {
+pub struct DerivationDriver<O: CommsClient + Send + Sync + Debug> {
     /// The current L2 safe head.
     l2_safe_head: L2BlockInfo,
     /// The header of the L2 safe head.
     l2_safe_head_header: Sealed<Header>,
     /// The inner pipeline.
-    pipeline: OraclePipeline,
+    pipeline: OraclePipeline<O>,
 }
 
-impl DerivationDriver {
+impl<O: CommsClient + Send + Sync + Debug> DerivationDriver<O> {
     /// Returns the current L2 safe head [L2BlockInfo].
     pub fn l2_safe_head(&self) -> &L2BlockInfo {
         &self.l2_safe_head
@@ -92,10 +93,10 @@ impl DerivationDriver {
     /// - A new [DerivationDriver] instance.
     pub async fn new(
         boot_info: &BootInfo,
-        caching_oracle: &CachingOracle,
-        blob_provider: OracleBlobProvider,
-        mut chain_provider: OracleL1ChainProvider,
-        mut l2_chain_provider: OracleL2ChainProvider,
+        caching_oracle: &O,
+        blob_provider: OracleBlobProvider<O>,
+        mut chain_provider: OracleL1ChainProvider<O>,
+        mut l2_chain_provider: OracleL2ChainProvider<O>,
     ) -> Result<Self> {
         let cfg = Arc::new(boot_info.rollup_config.clone());
 
@@ -142,7 +143,7 @@ impl DerivationDriver {
                 }
             }
 
-            attributes = self.pipeline.next();
+            attributes = self.pipeline.next_attributes();
         }
 
         Ok(attributes.expect("Must be some"))
@@ -159,13 +160,13 @@ impl DerivationDriver {
     /// ## Returns
     /// - A tuple containing the L1 origin block information and the L2 safe head information.
     async fn find_startup_info(
-        caching_oracle: &CachingOracle,
+        caching_oracle: &O,
         boot_info: &BootInfo,
-        chain_provider: &mut OracleL1ChainProvider,
-        l2_chain_provider: &mut OracleL2ChainProvider,
+        chain_provider: &mut OracleL1ChainProvider<O>,
+        l2_chain_provider: &mut OracleL2ChainProvider<O>,
     ) -> Result<(BlockInfo, L2BlockInfo, Sealed<Header>)> {
         // Find the initial safe head, based off of the starting L2 block number in the boot info.
-        HINT_WRITER
+        caching_oracle
             .write(&HintType::StartingL2Output.encode_with(&[boot_info.l2_output_root.as_ref()]))
             .await?;
         let mut output_preimage = [0u8; 128];
diff --git a/bin/client/src/l2/chain_provider.rs b/bin/client/src/l2/chain_provider.rs
index 92cf3e9..f540ae2 100644
--- a/bin/client/src/l2/chain_provider.rs
+++ b/bin/client/src/l2/chain_provider.rs
@@ -1,16 +1,16 @@
 //! Contains the concrete implementation of the [L2ChainProvider] trait for the client program.
 
-use crate::{BootInfo, CachingOracle, HintType, HINT_WRITER};
+use crate::{BootInfo, HintType};
 use alloc::{boxed::Box, sync::Arc, vec::Vec};
 use alloy_consensus::Header;
 use alloy_eips::eip2718::Decodable2718;
-use alloy_primitives::{Bytes, B256};
+use alloy_primitives::{Address, Bytes, B256};
 use alloy_rlp::Decodable;
 use anyhow::{anyhow, Result};
 use async_trait::async_trait;
 use kona_derive::traits::L2ChainProvider;
-use kona_mpt::{OrderedListWalker, TrieDBFetcher};
-use kona_preimage::{HintWriterClient, PreimageKey, PreimageKeyType, PreimageOracleClient};
+use kona_mpt::{OrderedListWalker, TrieDBFetcher, TrieDBHinter};
+use kona_preimage::{CommsClient, PreimageKey, PreimageKeyType};
 use kona_primitives::{
     L2BlockInfo, L2ExecutionPayloadEnvelope, OpBlock, RollupConfig, SystemConfig,
 };
@@ -18,26 +18,26 @@ use op_alloy_consensus::OpTxEnvelope;
 
 /// The oracle-backed L2 chain provider for the client program.
 #[derive(Debug, Clone)]
-pub struct OracleL2ChainProvider {
+pub struct OracleL2ChainProvider<T: CommsClient> {
     /// The boot information
     boot_info: Arc<BootInfo>,
     /// The preimage oracle client.
-    oracle: Arc<CachingOracle>,
+    oracle: Arc<T>,
 }
 
-impl OracleL2ChainProvider {
+impl<T: CommsClient> OracleL2ChainProvider<T> {
     /// Creates a new [OracleL2ChainProvider] with the given boot information and oracle client.
-    pub fn new(boot_info: Arc<BootInfo>, oracle: Arc<CachingOracle>) -> Self {
+    pub fn new(boot_info: Arc<BootInfo>, oracle: Arc<T>) -> Self {
         Self { boot_info, oracle }
     }
 }
 
-impl OracleL2ChainProvider {
+impl<T: CommsClient> OracleL2ChainProvider<T> {
     /// Returns a [Header] corresponding to the given L2 block number, by walking back from the
     /// L2 safe head.
     async fn header_by_number(&mut self, block_number: u64) -> Result<Header> {
         // Fetch the starting L2 output preimage.
-        HINT_WRITER
+        self.oracle
             .write(
                 &HintType::StartingL2Output.encode_with(&[self.boot_info.l2_output_root.as_ref()]),
             )
@@ -68,7 +68,7 @@ impl OracleL2ChainProvider {
 }
 
 #[async_trait]
-impl L2ChainProvider for OracleL2ChainProvider {
+impl<T: CommsClient + Send + Sync> L2ChainProvider for OracleL2ChainProvider<T> {
     async fn l2_block_info_by_number(&mut self, number: u64) -> Result<L2BlockInfo> {
         // Get the payload at the given block number.
         let payload = self.payload_by_number(number).await?;
@@ -84,7 +84,7 @@ impl L2ChainProvider for OracleL2ChainProvider {
         let header_hash = header.hash_slow();
 
         // Fetch the transactions in the block.
-        HINT_WRITER.write(&HintType::L2Transactions.encode_with(&[header_hash.as_ref()])).await?;
+        self.oracle.write(&HintType::L2Transactions.encode_with(&[header_hash.as_ref()])).await?;
         let trie_walker = OrderedListWalker::try_new_hydrated(transactions_root, self)?;
 
         // Decode the transactions within the transactions trie.
@@ -118,7 +118,7 @@ impl L2ChainProvider for OracleL2ChainProvider {
     }
 }
 
-impl TrieDBFetcher for OracleL2ChainProvider {
+impl<T: CommsClient> TrieDBFetcher for OracleL2ChainProvider<T> {
     fn trie_node_preimage(&self, key: B256) -> Result<Bytes> {
         // On L2, trie node preimages are stored as keccak preimage types in the oracle. We assume
         // that a hint for these preimages has already been sent, prior to this call.
@@ -133,7 +133,7 @@ impl TrieDBFetcher for OracleL2ChainProvider {
     fn bytecode_by_hash(&self, hash: B256) -> Result<Bytes> {
         // Fetch the bytecode preimage from the caching oracle.
         kona_common::block_on(async move {
-            HINT_WRITER.write(&HintType::L2Code.encode_with(&[hash.as_ref()])).await?;
+            self.oracle.write(&HintType::L2Code.encode_with(&[hash.as_ref()])).await?;
 
             self.oracle
                 .get(PreimageKey::new(*hash, PreimageKeyType::Keccak256))
@@ -145,7 +145,7 @@ impl TrieDBFetcher for OracleL2ChainProvider {
     fn header_by_hash(&self, hash: B256) -> Result<Header> {
         // Fetch the header from the caching oracle.
         kona_common::block_on(async move {
-            HINT_WRITER.write(&HintType::L2BlockHeader.encode_with(&[hash.as_ref()])).await?;
+            self.oracle.write(&HintType::L2BlockHeader.encode_with(&[hash.as_ref()])).await?;
 
             let header_bytes =
                 self.oracle.get(PreimageKey::new(*hash, PreimageKeyType::Keccak256)).await?;
@@ -154,3 +154,39 @@ impl TrieDBFetcher for OracleL2ChainProvider {
         })
     }
 }
+
+impl<T: CommsClient> TrieDBHinter for OracleL2ChainProvider<T> {
+    fn hint_trie_node(&self, hash: B256) -> Result<()> {
+        kona_common::block_on(async move {
+            self.oracle.write(&HintType::L2StateNode.encode_with(&[hash.as_slice()])).await
+        })
+    }
+
+    fn hint_account_proof(&self, address: Address, block_number: u64) -> Result<()> {
+        kona_common::block_on(async move {
+            self.oracle
+                .write(
+                    &HintType::L2AccountProof
+                        .encode_with(&[block_number.to_be_bytes().as_ref(), address.as_slice()]),
+                )
+                .await
+        })
+    }
+
+    fn hint_storage_proof(
+        &self,
+        address: alloy_primitives::Address,
+        slot: alloy_primitives::U256,
+        block_number: u64,
+    ) -> Result<()> {
+        kona_common::block_on(async move {
+            self.oracle
+                .write(&HintType::L2AccountStorageProof.encode_with(&[
+                    block_number.to_be_bytes().as_ref(),
+                    address.as_slice(),
+                    slot.to_be_bytes::<32>().as_ref(),
+                ]))
+                .await
+        })
+    }
+}
diff --git a/bin/client/src/l2/mod.rs b/bin/client/src/l2/mod.rs
index 31ceb93..459e4df 100644
--- a/bin/client/src/l2/mod.rs
+++ b/bin/client/src/l2/mod.rs
@@ -1,7 +1,4 @@
 //! Contains the L2-specifc contstructs of the client program.
 
-mod trie_hinter;
-pub use trie_hinter::TrieDBHintWriter;
-
 mod chain_provider;
 pub use chain_provider::OracleL2ChainProvider;
diff --git a/bin/client/src/l2/trie_hinter.rs b/bin/client/src/l2/trie_hinter.rs
deleted file mode 100644
index 53e9ecf..0000000
--- a/bin/client/src/l2/trie_hinter.rs
+++ /dev/null
@@ -1,51 +0,0 @@
-//! Contains the hinter for the [TrieDB].
-//!
-//! [TrieDB]: kona_mpt::TrieDB
-
-use crate::{HintType, HINT_WRITER};
-use alloy_primitives::{Address, B256};
-use anyhow::Result;
-use kona_mpt::TrieDBHinter;
-use kona_preimage::HintWriterClient;
-
-/// The [TrieDBHinter] implementation for the block executor's [TrieDB].
-///
-/// [TrieDB]: kona_mpt::TrieDB
-#[derive(Debug)]
-pub struct TrieDBHintWriter;
-
-impl TrieDBHinter for TrieDBHintWriter {
-    fn hint_trie_node(&self, hash: B256) -> Result<()> {
-        kona_common::block_on(async move {
-            HINT_WRITER.write(&HintType::L2StateNode.encode_with(&[hash.as_slice()])).await
-        })
-    }
-
-    fn hint_account_proof(&self, address: Address, block_number: u64) -> Result<()> {
-        kona_common::block_on(async move {
-            HINT_WRITER
-                .write(
-                    &HintType::L2AccountProof
-                        .encode_with(&[block_number.to_be_bytes().as_ref(), address.as_slice()]),
-                )
-                .await
-        })
-    }
-
-    fn hint_storage_proof(
-        &self,
-        address: alloy_primitives::Address,
-        slot: alloy_primitives::U256,
-        block_number: u64,
-    ) -> Result<()> {
-        kona_common::block_on(async move {
-            HINT_WRITER
-                .write(&HintType::L2AccountStorageProof.encode_with(&[
-                    block_number.to_be_bytes().as_ref(),
-                    address.as_slice(),
-                    slot.to_be_bytes::<32>().as_ref(),
-                ]))
-                .await
-        })
-    }
-}
diff --git a/crates/derive/Cargo.toml b/crates/derive/Cargo.toml
index 581a8c8..1954977 100644
--- a/crates/derive/Cargo.toml
+++ b/crates/derive/Cargo.toml
@@ -48,10 +48,6 @@ alloy-rpc-types = { version = "0.1", default-features = false, optional = true }
 serde_json = { version = "1.0.94", default-features = false, optional = true }
 reqwest = { version = "0.12.4", default-features = false, optional = true }
 
-# `metrics` feature dependencies
-lazy_static = { version = "1.5.0", optional = true }
-prometheus = { version = "0.13.4", features = ["process"], optional = true }
-
 # `test-utils` feature dependencies
 alloy-node-bindings = { version = "0.1", default-features = false, optional = true }
 tracing-subscriber = { version = "0.3.18", optional = true }
@@ -75,7 +71,6 @@ serde = [
   "op-alloy-consensus/serde"
 ]
 k256 = ["alloy-primitives/k256", "alloy-consensus/k256", "op-alloy-consensus/k256"]
-metrics = ["dep:prometheus", "dep:lazy_static"]
 online = [
   "dep:serde_json",
   "dep:revm",
diff --git a/crates/derive/README.md b/crates/derive/README.md
index 505439b..a4e7e7c 100644
--- a/crates/derive/README.md
+++ b/crates/derive/README.md
@@ -1,9 +1,6 @@
 # `kona-derive`
 
-  <a href="https://github.com/ethereum-optimism/kona/actions/workflows/rust_ci.yaml"><img src="https://github.com/ethereum-optimism/kona/actions/workflows/rust_ci.yaml/badge.svg?label=ci" alt="CI"></a>
-  <a href="https://github.com/ethereum-optimism/kona/actions/workflows/fpvm_tests.yaml"><img src="https://github.com/ethereum-optimism/kona/actions/workflows/fpvm_tests.yaml/badge.svg?label=FPVM Tests" alt="FPVM Tests"></a>
-    <a href="https://crates.io/crates/kona-derive"><img src="https://img.shields.io/crates/v/kona-derive.svg?label=kona-derive&labelColor=2a2f35" alt="Kona Derive"></a>
-  <img src="https://img.shields.io/badge/License-MIT-green.svg?label=license&labelColor=2a2f35" alt="License">
+> **Notice**: This crate is a WIP.
 
 A `no_std` compatible implementation of the OP Stack's [derivation pipeline][derive].
 
diff --git a/crates/derive/src/lib.rs b/crates/derive/src/lib.rs
index 1e5c76c..2f7a66e 100644
--- a/crates/derive/src/lib.rs
+++ b/crates/derive/src/lib.rs
@@ -2,12 +2,10 @@
 #![warn(missing_debug_implementations, missing_docs, unreachable_pub, rustdoc::all)]
 #![deny(unused_must_use, rust_2018_idioms)]
 #![cfg_attr(docsrs, feature(doc_cfg, doc_auto_cfg))]
-#![cfg_attr(not(any(test, feature = "metrics")), no_std)]
+#![no_std]
 
 extern crate alloc;
 
-mod macros;
-
 mod params;
 pub use params::{
     ChannelID, CHANNEL_ID_LENGTH, CONFIG_UPDATE_EVENT_VERSION_0, CONFIG_UPDATE_TOPIC,
@@ -24,6 +22,3 @@ pub mod types;
 
 #[cfg(feature = "online")]
 pub mod online;
-
-#[cfg(feature = "metrics")]
-pub mod metrics;
diff --git a/crates/derive/src/macros.rs b/crates/derive/src/macros.rs
deleted file mode 100644
index 4824659..0000000
--- a/crates/derive/src/macros.rs
+++ /dev/null
@@ -1,53 +0,0 @@
-//! Macros for use across derive.
-
-/// Starts the timer with a label value.
-#[macro_export]
-macro_rules! timer {
-    (START, $metric:ident, $labels:expr, $timer:ident) => {
-        #[cfg(feature = "metrics")]
-        let $timer = $crate::metrics::$metric.with_label_values($labels).start_timer();
-    };
-    (DISCARD, $timer:ident) => {
-        #[cfg(feature = "metrics")]
-        $timer.stop_and_discard();
-    };
-    (STOP, $timer:ident) => {
-        #[cfg(feature = "metrics")]
-        $timer.stop_and_record();
-    };
-}
-
-/// Increments a metric with a label value.
-#[macro_export]
-macro_rules! inc {
-    ($metric:ident, $labels:expr) => {
-        #[cfg(feature = "metrics")]
-        $crate::metrics::$metric.with_label_values($labels).inc();
-    };
-    ($metric:ident, $value:expr, $labels:expr) => {
-        #[cfg(feature = "metrics")]
-        $crate::metrics::$metric.with_label_values($labels).add($value);
-    };
-}
-
-/// Observes a metric with a label value.
-#[macro_export]
-macro_rules! observe {
-    ($metric:ident, $value:expr) => {
-        #[cfg(feature = "metrics")]
-        $crate::metrics::$metric.observe($value);
-    };
-    ($metric:ident, $value:expr, $labels:expr) => {
-        #[cfg(feature = "metrics")]
-        $crate::metrics::$metric.with_label_values($label).observe($value);
-    };
-}
-
-/// Sets a metric value.
-#[macro_export]
-macro_rules! set {
-    ($metric:ident, $value:expr) => {
-        #[cfg(feature = "metrics")]
-        $crate::metrics::$metric.set($value);
-    };
-}
diff --git a/crates/derive/src/metrics.rs b/crates/derive/src/metrics.rs
deleted file mode 100644
index 0525757..0000000
--- a/crates/derive/src/metrics.rs
+++ /dev/null
@@ -1,82 +0,0 @@
-//! Metrics for derivation pipeline stages.
-
-use alloc::{boxed::Box, string::String};
-use lazy_static::lazy_static;
-use prometheus::{
-    self, opts, register_counter_vec, register_gauge_vec, register_histogram,
-    register_histogram_vec, register_int_gauge, CounterVec, GaugeVec, Histogram, HistogramVec,
-    IntGauge,
-};
-
-const RESPONSE_TIME_CUSTOM_BUCKETS: &[f64; 18] = &[
-    0.00001, 0.00005, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.008, 0.01, 0.02, 0.05, 0.08,
-    0.1, 0.2, 0.5, 0.8, 1.0,
-];
-
-lazy_static! {
-    /// Tracks the L1 origin for the L1 Traversal Stage.
-    pub static ref ORIGIN_GAUGE: IntGauge = register_int_gauge!(
-        "origin_gauge",
-        "Tracks the L1 origin for the L1 Traversal Stage"
-    ).expect("Origin Gauge failed to register");
-
-    /// Tracks batch reader errors.
-    pub static ref BATCH_READER_ERRORS: CounterVec = register_counter_vec!(
-        "batch_reader_errors",
-        "Number of batch reader errors",
-        &["error"]
-    ).expect("Batch Reader Errors failed to register");
-
-    /// Tracks the compression ratio of batches.
-    pub static ref BATCH_COMPRESSION_RATIO: IntGauge = register_int_gauge!(
-        "batch_compression_ratio",
-        "Compression ratio of batches"
-    ).expect("Batch Compression Ratio failed to register");
-
-    /// Tracks the number of provider method calls.
-    pub static ref PROVIDER_CALLS: CounterVec = register_counter_vec!(
-        "provider_calls",
-        "Number of provider method calls",
-        &["provider", "method"]
-    ).expect("Provider Calls failed to register");
-
-    /// Tracks the number of errors in provider methods.
-    pub static ref PROVIDER_ERRORS: CounterVec = register_counter_vec!(
-        "provider_errors",
-        "Number of provider errors",
-        &["provider", "method", "error"]
-    ).expect("Provider Errors failed to register");
-
-    /// Tracks the time taken for provider methods.
-    pub static ref PROVIDER_RESPONSE_TIME: HistogramVec = register_histogram_vec!(
-        "provider_response_time_seconds",
-        "Provider response times",
-        &["provider", "method"],
-        RESPONSE_TIME_CUSTOM_BUCKETS.to_vec()
-    )
-    .expect("Failed to register histogram vec");
-
-    /// Tracks the time taken for stage advance methods.
-    pub static ref STAGE_ADVANCE_RESPONSE_TIME: HistogramVec = register_histogram_vec!(
-        "stage_advance_response_time_seconds",
-        "Stage advance response times",
-        &["stage"],
-        RESPONSE_TIME_CUSTOM_BUCKETS.to_vec()
-    ).expect("Failed to register histogram vec");
-
-    /// Tracks the number of derived frames.
-    pub static ref DERIVED_FRAMES_COUNT: GaugeVec = {
-        let opts = opts!("derived_frames_count", "Number of derived frames");
-        register_gauge_vec!(opts, &["status"]).expect("Derived Frames Count failed to register")
-    };
-
-    /// Tracks the number of channel timeouts.
-    pub static ref CHANNEL_TIMEOUTS: Histogram = {
-        let channel_timeout_buckets: [f64; 100] = core::array::from_fn(|i| (i * 10) as f64);
-        register_histogram!(
-            "channel_timeouts",
-            "Channel timeouts",
-            channel_timeout_buckets.to_vec()
-        ).expect("Failed to register histogram vec")
-    };
-}
diff --git a/crates/derive/src/online/alloy_providers.rs b/crates/derive/src/online/alloy_providers.rs
index 1d8383b..6d8ab61 100644
--- a/crates/derive/src/online/alloy_providers.rs
+++ b/crates/derive/src/online/alloy_providers.rs
@@ -65,71 +65,25 @@ impl AlloyChainProvider {
 #[async_trait]
 impl ChainProvider for AlloyChainProvider {
     async fn header_by_hash(&mut self, hash: B256) -> Result<Header> {
-        crate::inc!(PROVIDER_CALLS, &["chain_provider", "header_by_hash"]);
-        crate::timer!(START, PROVIDER_RESPONSE_TIME, &["chain_provider", "header_by_hash"], timer);
         if let Some(header) = self.header_by_hash_cache.get(&hash) {
             return Ok(header.clone());
         }
 
         let raw_header: TransportResult<Bytes> =
             self.inner.raw_request("debug_getRawHeader".into(), [hash]).await;
-        let raw_header: Bytes = match raw_header.map_err(|e| anyhow!(e)) {
-            Ok(b) => b,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(
-                    PROVIDER_ERRORS,
-                    &["chain_provider", "header_by_hash", "debug_getRawHeader"]
-                );
-                return Err(e);
-            }
-        };
-        match Header::decode(&mut raw_header.as_ref()).map_err(|e| anyhow!(e)) {
-            Ok(header) => {
-                self.header_by_hash_cache.put(hash, header.clone());
-                Ok(header)
-            }
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(PROVIDER_ERRORS, &["chain_provider", "header_by_hash", "decode"]);
-                Err(e)
-            }
-        }
+        let raw_header: Bytes = raw_header.map_err(|e| anyhow!(e))?;
+        Header::decode(&mut raw_header.as_ref()).map_err(|e| anyhow!(e))
     }
 
     async fn block_info_by_number(&mut self, number: u64) -> Result<BlockInfo> {
-        crate::inc!(PROVIDER_CALLS, &["chain_provider", "block_info_by_number"]);
-        crate::timer!(
-            START,
-            PROVIDER_RESPONSE_TIME,
-            &["chain_provider", "block_info_by_number"],
-            timer
-        );
         if let Some(block_info) = self.block_info_by_number_cache.get(&number) {
             return Ok(*block_info);
         }
 
         let raw_header: TransportResult<Bytes> =
             self.inner.raw_request("debug_getRawHeader".into(), [U64::from(number)]).await;
-        let raw_header: Bytes = match raw_header.map_err(|e| anyhow!(e)) {
-            Ok(b) => b,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(
-                    PROVIDER_ERRORS,
-                    &["chain_provider", "block_info_by_number", "debug_getRawHeader"]
-                );
-                return Err(e);
-            }
-        };
-        let header = match Header::decode(&mut raw_header.as_ref()).map_err(|e| anyhow!(e)) {
-            Ok(h) => h,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(PROVIDER_ERRORS, &["chain_provider", "block_info_by_number", "decode"]);
-                return Err(e);
-            }
-        };
+        let raw_header: Bytes = raw_header.map_err(|e| anyhow!(e))?;
+        let header = Header::decode(&mut raw_header.as_ref()).map_err(|e| anyhow!(e))?;
 
         let block_info = BlockInfo {
             hash: header.hash_slow(),
@@ -142,32 +96,15 @@ impl ChainProvider for AlloyChainProvider {
     }
 
     async fn receipts_by_hash(&mut self, hash: B256) -> Result<Vec<Receipt>> {
-        crate::inc!(PROVIDER_CALLS, &["chain_provider", "receipts_by_hash"]);
-        crate::timer!(
-            START,
-            PROVIDER_RESPONSE_TIME,
-            &["chain_provider", "receipts_by_hash"],
-            timer
-        );
         if let Some(receipts) = self.receipts_by_hash_cache.get(&hash) {
             return Ok(receipts.clone());
         }
 
         let raw_receipts: TransportResult<Vec<Bytes>> =
             self.inner.raw_request("debug_getRawReceipts".into(), [hash]).await;
-        let raw_receipts: Vec<Bytes> = match raw_receipts.map_err(|e| anyhow!(e)) {
-            Ok(r) => r,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(
-                    PROVIDER_ERRORS,
-                    &["chain_provider", "receipts_by_hash", "debug_getRawReceipts"]
-                );
-                return Err(e);
-            }
-        };
+        let raw_receipts: Vec<Bytes> = raw_receipts.map_err(|e| anyhow!(e))?;
 
-        let receipts = match raw_receipts
+        let receipts = raw_receipts
             .iter()
             .map(|r| {
                 let r = &mut r.as_ref();
@@ -179,15 +116,7 @@ impl ChainProvider for AlloyChainProvider {
 
                 Ok(ReceiptWithBloom::decode(r).map_err(|e| anyhow!(e))?.receipt)
             })
-            .collect::<Result<Vec<_>>>()
-        {
-            Ok(r) => r,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(PROVIDER_ERRORS, &["chain_provider", "receipts_by_hash", "decode"]);
-                return Err(e);
-            }
-        };
+            .collect::<Result<Vec<_>>>()?;
         self.receipts_by_hash_cache.put(hash, receipts.clone());
         Ok(receipts)
     }
@@ -196,13 +125,6 @@ impl ChainProvider for AlloyChainProvider {
         &mut self,
         hash: B256,
     ) -> Result<(BlockInfo, Vec<TxEnvelope>)> {
-        crate::inc!(PROVIDER_CALLS, &["chain_provider", "block_info_and_transactions_by_hash"]);
-        crate::timer!(
-            START,
-            PROVIDER_RESPONSE_TIME,
-            &["chain_provider", "block_info_and_transactions_by_hash"],
-            timer
-        );
         if let Some(block_info_and_txs) = self.block_info_and_transactions_by_hash_cache.get(&hash)
         {
             return Ok(block_info_and_txs.clone());
@@ -210,28 +132,8 @@ impl ChainProvider for AlloyChainProvider {
 
         let raw_block: TransportResult<Bytes> =
             self.inner.raw_request("debug_getRawBlock".into(), [hash]).await;
-        let raw_block: Bytes = match raw_block.map_err(|e| anyhow!(e)) {
-            Ok(b) => b,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(
-                    PROVIDER_ERRORS,
-                    &["chain_provider", "block_info_and_transactions_by_hash", "debug_getRawBlock"]
-                );
-                return Err(e);
-            }
-        };
-        let block = match Block::decode(&mut raw_block.as_ref()).map_err(|e| anyhow!(e)) {
-            Ok(b) => b,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(
-                    PROVIDER_ERRORS,
-                    &["chain_provider", "block_info_and_transactions_by_hash", "decode"]
-                );
-                return Err(e);
-            }
-        };
+        let raw_block: Bytes = raw_block.map_err(|e| anyhow!(e))?;
+        let block = Block::decode(&mut raw_block.as_ref()).map_err(|e| anyhow!(e))?;
 
         let block_info = BlockInfo {
             hash: block.header.hash_slow(),
@@ -297,76 +199,25 @@ impl AlloyL2ChainProvider {
 #[async_trait]
 impl L2ChainProvider for AlloyL2ChainProvider {
     async fn l2_block_info_by_number(&mut self, number: u64) -> Result<L2BlockInfo> {
-        crate::inc!(PROVIDER_CALLS, &["l2_chain_provider", "l2_block_info_by_number"]);
-        crate::timer!(
-            START,
-            PROVIDER_RESPONSE_TIME,
-            &["l2_chain_provider", "l2_block_info_by_number"],
-            timer
-        );
         if let Some(l2_block_info) = self.l2_block_info_by_number_cache.get(&number) {
             return Ok(*l2_block_info);
         }
 
-        let payload = match self.payload_by_number(number).await {
-            Ok(p) => p,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(
-                    PROVIDER_ERRORS,
-                    &["l2_chain_provider", "l2_block_info_by_number", "payload_by_number"]
-                );
-                return Err(e);
-            }
-        };
-        let l2_block_info = match payload.to_l2_block_ref(self.rollup_config.as_ref()) {
-            Ok(b) => b,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(
-                    PROVIDER_ERRORS,
-                    &["l2_chain_provider", "l2_block_info_by_number", "to_l2_block_ref"]
-                );
-                return Err(e);
-            }
-        };
+        let payload = self.payload_by_number(number).await?;
+        let l2_block_info = payload.to_l2_block_ref(self.rollup_config.as_ref())?;
         self.l2_block_info_by_number_cache.put(number, l2_block_info);
         Ok(l2_block_info)
     }
 
     async fn payload_by_number(&mut self, number: u64) -> Result<L2ExecutionPayloadEnvelope> {
-        crate::inc!(PROVIDER_CALLS, &["l2_chain_provider", "payload_by_number"]);
-        crate::timer!(
-            START,
-            PROVIDER_RESPONSE_TIME,
-            &["l2_chain_provider", "payload_by_number"],
-            timer
-        );
         if let Some(payload) = self.payload_by_number_cache.get(&number) {
             return Ok(payload.clone());
         }
 
         let raw_block: TransportResult<Bytes> =
             self.inner.raw_request("debug_getRawBlock".into(), [U64::from(number)]).await;
-        let raw_block: Bytes = match raw_block.map_err(|e| anyhow!(e)) {
-            Ok(b) => b,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(
-                    PROVIDER_ERRORS,
-                    &["l2_chain_provider", "payload_by_number", "debug_getRawBlock"]
-                );
-                return Err(e);
-            }
-        };
-        let block = match OpBlock::decode(&mut raw_block.as_ref()).map_err(|e| anyhow!(e)) {
-            Ok(b) => b,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(PROVIDER_ERRORS, &["l2_chain_provider", "payload_by_number", "decode"]);
-                return Err(e);
-            }
-        };
+        let raw_block: Bytes = raw_block.map_err(|e| anyhow!(e))?;
+        let block = OpBlock::decode(&mut raw_block.as_ref()).map_err(|e| anyhow!(e))?;
         let payload_envelope: L2ExecutionPayloadEnvelope = block.into();
 
         self.payload_by_number_cache.put(number, payload_envelope.clone());
@@ -378,40 +229,11 @@ impl L2ChainProvider for AlloyL2ChainProvider {
         number: u64,
         rollup_config: Arc<RollupConfig>,
     ) -> Result<SystemConfig> {
-        crate::inc!(PROVIDER_CALLS, &["l2_chain_provider", "system_config_by_number"]);
-        crate::timer!(
-            START,
-            PROVIDER_RESPONSE_TIME,
-            &["l2_chain_provider", "system_config_by_number"],
-            timer
-        );
         if let Some(system_config) = self.system_config_by_number_cache.get(&number) {
             return Ok(system_config.clone());
         }
 
-        let envelope = match self.payload_by_number(number).await {
-            Ok(e) => e,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(
-                    PROVIDER_ERRORS,
-                    &["l2_chain_provider", "system_config_by_number", "payload_by_number"]
-                );
-                return Err(e);
-            }
-        };
-        let sys_config = match envelope.to_system_config(&rollup_config) {
-            Ok(s) => s,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(
-                    PROVIDER_ERRORS,
-                    &["l2_chain_provider", "system_config_by_number", "to_system_config"]
-                );
-                return Err(e);
-            }
-        };
-        self.system_config_by_number_cache.put(number, sys_config.clone());
-        Ok(sys_config)
+        let envelope = self.payload_by_number(number).await?;
+        envelope.to_system_config(&rollup_config)
     }
 }
diff --git a/crates/derive/src/online/beacon_client.rs b/crates/derive/src/online/beacon_client.rs
index 407fb27..f36a201 100644
--- a/crates/derive/src/online/beacon_client.rs
+++ b/crates/derive/src/online/beacon_client.rs
@@ -56,57 +56,25 @@ impl OnlineBeaconClient {
 #[async_trait]
 impl BeaconClient for OnlineBeaconClient {
     async fn config_spec(&self) -> Result<APIConfigResponse> {
-        crate::inc!(PROVIDER_CALLS, &["beacon_client", "config_spec"]);
-        crate::timer!(START, PROVIDER_RESPONSE_TIME, &["beacon_client", "config_spec"], timer);
-        let first = match self
-            .inner
+        self.inner
             .get(format!("{}/{}", self.base, SPEC_METHOD))
             .send()
             .await
+            .map_err(|e| anyhow!(e))?
+            .json::<APIConfigResponse>()
+            .await
             .map_err(|e| anyhow!(e))
-        {
-            Ok(response) => response,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(PROVIDER_ERRORS, &["beacon_client", "config_spec", "request"]);
-                return Err(e);
-            }
-        };
-        match first.json::<APIConfigResponse>().await.map_err(|e| anyhow!(e)) {
-            Ok(response) => Ok(response),
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(PROVIDER_ERRORS, &["beacon_client", "config_spec", "decode"]);
-                Err(e)
-            }
-        }
     }
 
     async fn beacon_genesis(&self) -> Result<APIGenesisResponse> {
-        crate::inc!(PROVIDER_CALLS, &["beacon_client", "beacon_genesis"]);
-        crate::timer!(START, PROVIDER_RESPONSE_TIME, &["beacon_client", "beacon_genesis"], timer);
-        let first = match self
-            .inner
+        self.inner
             .get(format!("{}/{}", self.base, GENESIS_METHOD))
             .send()
             .await
+            .map_err(|e| anyhow!(e))?
+            .json::<APIGenesisResponse>()
+            .await
             .map_err(|e| anyhow!(e))
-        {
-            Ok(response) => response,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(PROVIDER_ERRORS, &["beacon_client", "beacon_genesis", "request"]);
-                return Err(e);
-            }
-        };
-        match first.json::<APIGenesisResponse>().await.map_err(|e| anyhow!(e)) {
-            Ok(response) => Ok(response),
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(PROVIDER_ERRORS, &["beacon_client", "beacon_genesis", "decode"]);
-                Err(e)
-            }
-        }
     }
 
     async fn beacon_blob_side_cars(
@@ -114,42 +82,15 @@ impl BeaconClient for OnlineBeaconClient {
         slot: u64,
         hashes: &[IndexedBlobHash],
     ) -> Result<Vec<APIBlobSidecar>> {
-        crate::inc!(PROVIDER_CALLS, &["beacon_client", "beacon_blob_side_cars"]);
-        crate::timer!(
-            START,
-            PROVIDER_RESPONSE_TIME,
-            &["beacon_client", "beacon_blob_side_cars"],
-            timer
-        );
-        let raw_response = match self
+        let raw_response = self
             .inner
             .get(format!("{}/{}/{}", self.base, SIDECARS_METHOD_PREFIX, slot))
             .send()
             .await
-            .map_err(|e| anyhow!(e))
-        {
-            Ok(response) => response,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(
-                    PROVIDER_ERRORS,
-                    &["beacon_client", "beacon_blob_side_cars", "request"]
-                );
-                return Err(e);
-            }
-        };
-        let raw_response = match raw_response
+            .map_err(|e| anyhow!(e))?
             .json::<APIGetBlobSidecarsResponse>()
             .await
-            .map_err(|e| anyhow!(e))
-        {
-            Ok(response) => response,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(PROVIDER_ERRORS, &["beacon_client", "beacon_blob_side_cars", "decode"]);
-                return Err(e);
-            }
-        };
+            .map_err(|e| anyhow!(e))?;
 
         let mut sidecars = Vec::with_capacity(hashes.len());
 
diff --git a/crates/derive/src/online/blob_provider.rs b/crates/derive/src/online/blob_provider.rs
index eb725ed..e8653f5 100644
--- a/crates/derive/src/online/blob_provider.rs
+++ b/crates/derive/src/online/blob_provider.rs
@@ -128,31 +128,15 @@ where
         block_ref: &BlockInfo,
         blob_hashes: &[IndexedBlobHash],
     ) -> Result<Vec<Blob>, BlobProviderError> {
-        crate::inc!(PROVIDER_CALLS, &["blob_provider", "get_blobs"]);
-        crate::timer!(START, PROVIDER_RESPONSE_TIME, &["blob_provider", "get_blobs"], timer);
         // Fetches the genesis timestamp and slot interval from the
         // [BeaconGenesis] and [ConfigSpec] if not previously loaded.
-        if let Err(e) = self.load_configs().await {
-            crate::timer!(DISCARD, timer);
-            crate::inc!(PROVIDER_ERRORS, &["blob_provider", "get_blobs", "load_configs"]);
-            return Err(e);
-        }
+        self.load_configs().await?;
 
         // Fetch the blob sidecars for the given block reference and blob hashes.
-        let sidecars = match self.fetch_filtered_sidecars(block_ref, blob_hashes).await {
-            Ok(sidecars) => sidecars,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(
-                    PROVIDER_ERRORS,
-                    &["blob_provider", "get_blobs", "fetch_filtered_sidecars"]
-                );
-                return Err(e);
-            }
-        };
+        let sidecars = self.fetch_filtered_sidecars(block_ref, blob_hashes).await?;
 
         // Validate the blob sidecars straight away with the `IndexedBlobHash`es.
-        let blobs = match sidecars
+        let blobs = sidecars
             .into_iter()
             .enumerate()
             .map(|(i, sidecar)| {
@@ -162,15 +146,7 @@ where
                     Err(e) => Err(e),
                 }
             })
-            .collect::<anyhow::Result<Vec<Blob>>>()
-        {
-            Ok(blobs) => blobs,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                crate::inc!(PROVIDER_ERRORS, &["blob_provider", "get_blobs", "verify_blob"]);
-                return Err(BlobProviderError::Custom(e));
-            }
-        };
+            .collect::<anyhow::Result<Vec<Blob>>>()?;
 
         Ok(blobs)
     }
diff --git a/crates/derive/src/pipeline/core.rs b/crates/derive/src/pipeline/core.rs
index 3490e8c..4852ef9 100644
--- a/crates/derive/src/pipeline/core.rs
+++ b/crates/derive/src/pipeline/core.rs
@@ -56,13 +56,8 @@ where
     S: NextAttributes + ResettableStage + OriginProvider + OriginAdvancer + Debug + Send + Sync,
     P: L2ChainProvider + Send + Sync + Debug,
 {
-    /// Peeks at the next prepared [L2AttributesWithParent] from the pipeline.
-    fn peek(&self) -> Option<&L2AttributesWithParent> {
-        self.prepared.front()
-    }
-
     /// Returns the next prepared [L2AttributesWithParent] from the pipeline.
-    fn next(&mut self) -> Option<L2AttributesWithParent> {
+    fn next_attributes(&mut self) -> Option<L2AttributesWithParent> {
         self.prepared.pop_front()
     }
 
diff --git a/crates/derive/src/stages/attributes_queue.rs b/crates/derive/src/stages/attributes_queue.rs
index 921c4e4..a1ae394 100644
--- a/crates/derive/src/stages/attributes_queue.rs
+++ b/crates/derive/src/stages/attributes_queue.rs
@@ -85,23 +85,11 @@ where
         &mut self,
         parent: L2BlockInfo,
     ) -> StageResult<L2AttributesWithParent> {
-        crate::timer!(START, STAGE_ADVANCE_RESPONSE_TIME, &["attributes_queue"], timer);
-        let batch = match self.load_batch(parent).await {
-            Ok(batch) => batch,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                return Err(e);
-            }
-        };
+        // Load the batch.
+        let batch = self.load_batch(parent).await?;
 
         // Construct the payload attributes from the loaded batch.
-        let attributes = match self.create_next_attributes(batch, parent).await {
-            Ok(attributes) => attributes,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                return Err(e);
-            }
-        };
+        let attributes = self.create_next_attributes(batch, parent).await?;
         let populated_attributes =
             L2AttributesWithParent { attributes, parent, is_last_in_span: self.is_last_in_span };
 
@@ -143,7 +131,6 @@ where
         attributes.transactions.extend(batch.transactions);
 
         info!(
-            target: "attributes-queue",
             "generated attributes in payload queue: txs={}, timestamp={}",
             tx_count, batch.timestamp
         );
@@ -209,7 +196,7 @@ where
         system_config: &SystemConfig,
     ) -> StageResult<()> {
         self.prev.reset(block_info, system_config).await?;
-        info!(target: "attributes-queue", "resetting attributes queue");
+        info!("resetting attributes queue");
         self.batch = None;
         self.is_last_in_span = false;
         Err(StageError::Eof)
diff --git a/crates/derive/src/stages/batch_queue.rs b/crates/derive/src/stages/batch_queue.rs
index 4000af6..8d7f89c 100644
--- a/crates/derive/src/stages/batch_queue.rs
+++ b/crates/derive/src/stages/batch_queue.rs
@@ -119,7 +119,7 @@ where
 
         // Get the epoch
         let epoch = self.l1_blocks[0];
-        info!(target: "batch-queue", "Deriving next batch for epoch: {}", epoch.number);
+        info!("Deriving next batch for epoch: {}", epoch.number);
 
         // Note: epoch origin can now be one block ahead of the L2 Safe Head
         // This is in the case where we auto generate all batches in an epoch & advance the epoch
@@ -151,7 +151,7 @@ where
                     remaining.push(batch.clone());
                 }
                 BatchValidity::Drop => {
-                    warn!(target: "batch-queue", "Dropping batch with parent: {}", parent.block_info);
+                    warn!("Dropping batch: {:?}, parent: {}", batch.batch, parent.block_info);
                     continue;
                 }
                 BatchValidity::Accept => {
@@ -171,7 +171,7 @@ where
         self.batches = remaining;
 
         if let Some(nb) = next_batch {
-            info!(target: "batch-queue", "Next batch found for timestamp {}", nb.batch.timestamp());
+            info!("Next batch found: {:?}", nb.batch);
             return Ok(nb.batch);
         }
 
@@ -190,7 +190,6 @@ where
         }
 
         info!(
-            target: "batch-queue",
             "Generating empty batches for epoch: {} | parent: {}",
             epoch.number, parent.l1_origin.number
         );
@@ -206,7 +205,7 @@ where
         // to preserve that L2 time >= L1 time. If this is the first block of the epoch, always
         // generate a batch to ensure that we at least have one batch per epoch.
         if next_timestamp < next_epoch.timestamp || first_of_epoch {
-            info!(target: "batch-queue", "Generating empty batch for epoch: {}", epoch.number);
+            info!("Generating empty batch for epoch: {}", epoch.number);
             return Ok(Batch::Single(SingleBatch {
                 parent_hash: parent.block_info.hash,
                 epoch_num: epoch.number,
@@ -219,7 +218,6 @@ where
         // At this point we have auto generated every batch for the current epoch
         // that we can, so we can advance to the next epoch.
         info!(
-            target: "batch-queue",
             "Advancing to next epoch: {}, timestamp: {}, epoch timestamp: {}",
             next_epoch.number, next_timestamp, next_epoch.timestamp
         );
@@ -230,7 +228,7 @@ where
     /// Adds a batch to the queue.
     pub async fn add_batch(&mut self, batch: Batch, parent: L2BlockInfo) -> StageResult<()> {
         if self.l1_blocks.is_empty() {
-            error!(target: "batch-queue", "Cannot add batch without an origin");
+            error!("Cannot add batch without an origin");
             panic!("Cannot add batch without an origin");
         }
         let origin = self.origin.ok_or_else(|| anyhow!("cannot add batch with missing origin"))?;
@@ -264,12 +262,10 @@ where
     /// Returns the next valid batch upon the given safe head.
     /// Also returns the boolean that indicates if the batch is the last block in the batch.
     async fn next_batch(&mut self, parent: L2BlockInfo) -> StageResult<SingleBatch> {
-        crate::timer!(START, STAGE_ADVANCE_RESPONSE_TIME, &["batch_queue"], timer);
         if !self.next_spans.is_empty() {
             // There are cached singular batches derived from the span batch.
             // Check if the next cached batch matches the given parent block.
             if self.next_spans[0].timestamp == parent.block_info.timestamp + self.cfg.block_time {
-                crate::timer!(DISCARD, timer);
                 return self
                     .pop_next_batch(parent)
                     .ok_or(anyhow!("failed to pop next batch from span batch").into());
@@ -278,7 +274,6 @@ where
             // Means the previously returned batch is invalid.
             // Drop cached batches and find another batch.
             warn!(
-                target: "batch-queue",
                 "Parent block does not match the next batch. Dropping {} cached batches.",
                 self.next_spans.len()
             );
@@ -294,7 +289,7 @@ where
             for (i, block) in self.l1_blocks.iter().enumerate() {
                 if parent.l1_origin.number == block.number {
                     self.l1_blocks.drain(0..i);
-                    info!(target: "batch-queue", "Advancing epoch");
+                    info!("Advancing epoch");
                     break;
                 }
             }
@@ -314,13 +309,7 @@ where
         if self.origin != self.prev.origin() {
             self.origin = self.prev.origin();
             if !origin_behind {
-                let origin = match self.origin.as_ref().ok_or_else(|| anyhow!("missing origin")) {
-                    Ok(o) => o,
-                    Err(e) => {
-                        crate::timer!(DISCARD, timer);
-                        return Err(StageError::Custom(e));
-                    }
-                };
+                let origin = self.origin.as_ref().ok_or_else(|| anyhow!("missing origin"))?;
                 self.l1_blocks.push(*origin);
             } else {
                 // This is to handle the special case of startup.
@@ -329,7 +318,7 @@ where
                 // reset is called, the origin behind is false.
                 self.l1_blocks.clear();
             }
-            info!(target: "batch-queue", "Advancing batch queue origin: {:?}", self.origin);
+            info!("Advancing batch queue origin: {:?}", self.origin);
         }
 
         // Load more data into the batch queue.
@@ -339,20 +328,16 @@ where
                 if !origin_behind {
                     self.add_batch(b, parent).await.ok();
                 } else {
-                    warn!(target: "batch-queue", "Dropping batch: Origin is behind");
+                    warn!("Dropping batch: Origin is behind");
                 }
             }
             Err(StageError::Eof) => out_of_data = true,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                return Err(e);
-            }
+            Err(e) => return Err(e),
         }
 
         // Skip adding the data unless up to date with the origin,
         // but still fully empty the previous stages.
         if origin_behind {
-            crate::timer!(DISCARD, timer);
             if out_of_data {
                 return Err(StageError::Eof);
             }
@@ -362,18 +347,15 @@ where
         // Attempt to derive more batches.
         let batch = match self.derive_next_batch(out_of_data, parent).await {
             Ok(b) => b,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                match e {
-                    StageError::Eof => {
-                        if out_of_data {
-                            return Err(StageError::Eof);
-                        }
-                        return Err(StageError::NotEnoughData);
+            Err(e) => match e {
+                StageError::Eof => {
+                    if out_of_data {
+                        return Err(StageError::Eof);
                     }
-                    _ => return Err(e),
+                    return Err(StageError::NotEnoughData);
                 }
-            }
+                _ => return Err(e),
+            },
         };
 
         // If the next batch is derived from the span batch, it's the last batch of the span.
@@ -381,28 +363,15 @@ where
         match batch {
             Batch::Single(sb) => Ok(sb),
             Batch::Span(sb) => {
-                let batches = match sb.get_singular_batches(&self.l1_blocks, parent).map_err(|e| {
+                let batches = sb.get_singular_batches(&self.l1_blocks, parent).map_err(|e| {
                     StageError::Custom(anyhow!(
                         "Could not get singular batches from span batch: {e}"
                     ))
-                }) {
-                    Ok(b) => b,
-                    Err(e) => {
-                        crate::timer!(DISCARD, timer);
-                        return Err(e);
-                    }
-                };
+                })?;
                 self.next_spans = batches;
-                let nb = match self
+                let nb = self
                     .pop_next_batch(parent)
-                    .ok_or_else(|| anyhow!("failed to pop next batch from span batch"))
-                {
-                    Ok(b) => b,
-                    Err(e) => {
-                        crate::timer!(DISCARD, timer);
-                        return Err(StageError::Custom(e));
-                    }
-                };
+                    .ok_or_else(|| anyhow!("failed to pop next batch from span batch"))?;
                 Ok(nb)
             }
         }
diff --git a/crates/derive/src/stages/channel_bank.rs b/crates/derive/src/stages/channel_bank.rs
index 801d8bc..a2c778c 100644
--- a/crates/derive/src/stages/channel_bank.rs
+++ b/crates/derive/src/stages/channel_bank.rs
@@ -12,7 +12,7 @@ use anyhow::anyhow;
 use async_trait::async_trait;
 use core::fmt::Debug;
 use hashbrown::HashMap;
-use tracing::{trace, warn};
+use tracing::{debug, warn};
 
 /// Provides frames for the [ChannelBank] stage.
 #[async_trait]
@@ -88,14 +88,14 @@ where
 
         // Check if the channel is not timed out. If it has, ignore the frame.
         if current_channel.open_block_number() + self.cfg.channel_timeout < origin.number {
-            warn!(target: "channel-bank", "Channel {:?} timed out", frame.id);
+            warn!("Channel {:?} timed out", frame.id);
             return Ok(());
         }
 
         // Ingest the frame. If it fails, ignore the frame.
         let frame_id = frame.id;
         if current_channel.add_frame(frame, origin).is_err() {
-            warn!(target: "channel-bank", "Failed to add frame to channel: {:?}", frame_id);
+            warn!("Failed to add frame to channel: {:?}", frame_id);
             return Ok(());
         }
 
@@ -108,7 +108,7 @@ where
     pub fn read(&mut self) -> StageResult<Option<Bytes>> {
         // Bail if there are no channels to read from.
         if self.channel_queue.is_empty() {
-            trace!(target: "channel-bank", "No channels to read from");
+            debug!("No channels to read from");
             return Err(StageError::Eof);
         }
 
@@ -118,8 +118,7 @@ where
         let channel = self.channels.get(&first).ok_or(StageError::ChannelNotFound)?;
         let origin = self.origin().ok_or(StageError::MissingOrigin)?;
         if channel.open_block_number() + self.cfg.channel_timeout < origin.number {
-            warn!(target: "channel-bank", "Channel {:?} timed out", first);
-            crate::observe!(CHANNEL_TIMEOUTS, (origin.number - channel.open_block_number()) as f64);
+            warn!("Channel {:?} timed out", first);
             self.channels.remove(&first);
             self.channel_queue.pop_front();
             return Ok(None);
@@ -180,29 +179,19 @@ where
     P: ChannelBankProvider + PreviousStage + Send + Debug,
 {
     async fn next_data(&mut self) -> StageResult<Option<Bytes>> {
-        crate::timer!(START, STAGE_ADVANCE_RESPONSE_TIME, &["channel_bank"], timer);
         match self.read() {
             Err(StageError::Eof) => {
                 // continue - we will attempt to load data into the channel bank
             }
             Err(e) => {
-                crate::timer!(DISCARD, timer);
                 return Err(anyhow!("Error fetching next data from channel bank: {:?}", e).into());
             }
             data => return data,
         };
 
         // Load the data into the channel bank
-        let frame = match self.prev.next_frame().await {
-            Ok(f) => f,
-            Err(e) => {
-                crate::timer!(DISCARD, timer);
-                return Err(e);
-            }
-        };
-        let res = self.ingest_frame(frame);
-        crate::timer!(DISCARD, timer);
-        res?;
+        let frame = self.prev.next_frame().await?;
+        self.ingest_frame(frame)?;
         Err(StageError::NotEnoughData)
     }
 }
diff --git a/crates/derive/src/stages/channel_reader.rs b/crates/derive/src/stages/channel_reader.rs
index bfc774f..4dc1f0f 100644
--- a/crates/derive/src/stages/channel_reader.rs
+++ b/crates/derive/src/stages/channel_reader.rs
@@ -12,7 +12,7 @@ use alloy_rlp::Decodable;
 use async_trait::async_trait;
 use core::fmt::Debug;
 use miniz_oxide::inflate::decompress_to_vec_zlib;
-use tracing::{debug, error, warn};
+use tracing::warn;
 
 /// ZLIB Deflate Compression Method.
 pub(crate) const ZLIB_DEFLATE_COMPRESSION_METHOD: u8 = 8;
@@ -88,11 +88,9 @@ where
     P: ChannelReaderProvider + PreviousStage + Send + Debug,
 {
     async fn next_batch(&mut self) -> StageResult<Batch> {
-        crate::timer!(START, STAGE_ADVANCE_RESPONSE_TIME, &["channel_reader"], timer);
         if let Err(e) = self.set_batch_reader().await {
-            debug!(target: "channel-reader", "Failed to set batch reader: {:?}", e);
+            warn!("Failed to set batch reader: {:?}", e);
             self.next_channel();
-            crate::timer!(DISCARD, timer);
             return Err(e);
         }
         match self
@@ -105,7 +103,6 @@ where
             Ok(batch) => Ok(batch),
             Err(e) => {
                 self.next_channel();
-                crate::timer!(DISCARD, timer);
                 Err(e)
             }
         }
@@ -161,14 +158,12 @@ impl BatchReader {
     pub(crate) fn next_batch(&mut self, cfg: &RollupConfig) -> Option<Batch> {
         // If the data is not already decompressed, decompress it.
         let mut brotli_used = false;
-        let mut raw_len = 0;
         if let Some(data) = self.data.take() {
             // Peek at the data to determine the compression type.
             if data.is_empty() {
-                warn!(target: "batch-reader", "Data is too short to determine compression type, skipping batch");
+                tracing::warn!(target: "batch-reader", "Data is too short to determine compression type, skipping batch");
                 return None;
             }
-            raw_len = data.len();
             let compression_type = data[0];
             if (compression_type & 0x0F) == ZLIB_DEFLATE_COMPRESSION_METHOD ||
                 (compression_type & 0x0F) == ZLIB_RESERVED_COMPRESSION_METHOD
@@ -178,8 +173,7 @@ impl BatchReader {
                 brotli_used = true;
                 self.decompressed = decompress_brotli(&data[1..]).ok()?;
             } else {
-                error!(target: "batch-reader", "Unsupported compression type: {:x}, skipping batch", compression_type);
-                crate::inc!(BATCH_READER_ERRORS, &["unsupported_compression_type"]);
+                tracing::error!(target: "batch-reader", "Unsupported compression type: {:x}, skipping batch", compression_type);
                 return None;
             }
         }
@@ -187,13 +181,11 @@ impl BatchReader {
         // Decompress and RLP decode the batch data, before finally decoding the batch itself.
         let decompressed_reader = &mut self.decompressed.as_slice()[self.cursor..].as_ref();
         let bytes = Bytes::decode(decompressed_reader).ok()?;
-        crate::set!(BATCH_COMPRESSION_RATIO, (raw_len as i64) * 100 / bytes.len() as i64);
         let batch = Batch::decode(&mut bytes.as_ref(), cfg).unwrap();
 
         // Confirm that brotli decompression was performed *after* the Fjord hardfork.
         if brotli_used && !cfg.is_fjord_active(batch.timestamp()) {
-            warn!(target: "batch-reader", "Brotli compression used before Fjord hardfork, skipping batch");
-            crate::inc!(BATCH_READER_ERRORS, &["brotli_used_before_fjord"]);
+            tracing::warn!(target: "batch-reader", "Brotli compression used before Fjord hardfork, skipping batch");
             return None;
         }
 
diff --git a/crates/derive/src/stages/frame_queue.rs b/crates/derive/src/stages/frame_queue.rs
index 830698b..edb7e44 100644
--- a/crates/derive/src/stages/frame_queue.rs
+++ b/crates/derive/src/stages/frame_queue.rs
@@ -10,7 +10,7 @@ use alloy_primitives::Bytes;
 use anyhow::anyhow;
 use async_trait::async_trait;
 use core::fmt::Debug;
-use tracing::{debug, error, trace};
+use tracing::{debug, error, warn};
 
 /// Provides data frames for the [FrameQueue] stage.
 #[async_trait]
@@ -71,17 +71,15 @@ where
             match self.prev.next_data().await {
                 Ok(data) => {
                     if let Ok(frames) = into_frames(Ok(data)) {
-                        crate::inc!(DERIVED_FRAMES_COUNT, frames.len() as f64, &["success"]);
                         self.queue.extend(frames);
                     } else {
-                        crate::inc!(DERIVED_FRAMES_COUNT, &["failed"]);
                         // There may be more frames in the queue for the
                         // pipeline to advance, so don't return an error here.
-                        error!(target: "frame-queue", "Failed to parse frames from data.");
+                        error!("Failed to parse frames from data.");
                     }
                 }
                 Err(e) => {
-                    debug!(target: "frame-queue", "Failed to retrieve data: {:?}", e);
+                    warn!("Failed to retrieve data: {:?}", e);
                     return Err(e); // Bubble up potential EOF error without wrapping.
                 }
             }
@@ -89,7 +87,7 @@ where
 
         // If we did not add more frames but still have more data, retry this function.
         if self.queue.is_empty() {
-            trace!(target: "frame-queue", "Queue is empty after fetching data. Retrying next_frame.");
+            debug!("Queue is empty after fetching data. Retrying next_frame.");
             return Err(StageError::NotEnoughData);
         }
 
diff --git a/crates/derive/src/stages/l1_traversal.rs b/crates/derive/src/stages/l1_traversal.rs
index d79a62a..3a61025 100644
--- a/crates/derive/src/stages/l1_traversal.rs
+++ b/crates/derive/src/stages/l1_traversal.rs
@@ -76,7 +76,7 @@ impl<F: ChainProvider + Send> OriginAdvancer for L1Traversal<F> {
         let block = match self.block {
             Some(block) => block,
             None => {
-                warn!(target: "l1-traversal",  "Missing current block, can't advance origin with no reference.");
+                warn!("L1Traversal: No block to advance to");
                 return Err(StageError::Eof);
             }
         };
@@ -104,7 +104,6 @@ impl<F: ChainProvider + Send> OriginAdvancer for L1Traversal<F> {
             return Err(StageError::SystemConfigUpdate(e));
         }
 
-        crate::set!(ORIGIN_GAUGE, next_l1_origin.number as i64);
         self.block = Some(next_l1_origin);
         self.done = false;
         Ok(())
diff --git a/crates/derive/src/traits/pipeline.rs b/crates/derive/src/traits/pipeline.rs
index 1c25dd3..7b7f3f4 100644
--- a/crates/derive/src/traits/pipeline.rs
+++ b/crates/derive/src/traits/pipeline.rs
@@ -8,11 +8,8 @@ use kona_primitives::{BlockInfo, L2AttributesWithParent, L2BlockInfo};
 /// This trait defines the interface for interacting with the derivation pipeline.
 #[async_trait]
 pub trait Pipeline: OriginProvider {
-    /// Peeks at the next [L2AttributesWithParent] from the pipeline.
-    fn peek(&self) -> Option<&L2AttributesWithParent>;
-
     /// Returns the next [L2AttributesWithParent] from the pipeline.
-    fn next(&mut self) -> Option<L2AttributesWithParent>;
+    fn next_attributes(&mut self) -> Option<L2AttributesWithParent>;
 
     /// Resets the pipeline on the next [Pipeline::step] call.
     async fn reset(&mut self, origin: BlockInfo) -> anyhow::Result<()>;
diff --git a/crates/derive/src/types/batch/span_batch/raw.rs b/crates/derive/src/types/batch/span_batch/raw.rs
index 8d9762e..997c606 100644
--- a/crates/derive/src/types/batch/span_batch/raw.rs
+++ b/crates/derive/src/types/batch/span_batch/raw.rs
@@ -139,6 +139,7 @@ impl RawSpanBatch {
 
 #[cfg(test)]
 mod test {
+    extern crate std;
     use super::{RawSpanBatch, RollupConfig, SpanBatch, SpanBatchElement};
     use alloc::{vec, vec::Vec};
     use alloy_primitives::FixedBytes;
diff --git a/crates/derive/src/types/channel.rs b/crates/derive/src/types/channel.rs
index f731b7a..0f719f5 100644
--- a/crates/derive/src/types/channel.rs
+++ b/crates/derive/src/types/channel.rs
@@ -154,6 +154,8 @@ mod test {
         vec::Vec,
     };
 
+    extern crate std;
+
     struct FrameValidityTestCase {
         name: String,
         frames: Vec<Frame>,
diff --git a/crates/derive/src/types/frame.rs b/crates/derive/src/types/frame.rs
index 24f4ed6..281d4bc 100644
--- a/crates/derive/src/types/frame.rs
+++ b/crates/derive/src/types/frame.rs
@@ -106,6 +106,8 @@ impl Frame {
 
 #[cfg(test)]
 mod test {
+    extern crate std;
+
     use super::*;
 
     #[test]
diff --git a/crates/executor/src/lib.rs b/crates/executor/src/lib.rs
index 77524ca..a5202d9 100644
--- a/crates/executor/src/lib.rs
+++ b/crates/executor/src/lib.rs
@@ -57,6 +57,8 @@ where
     pub fn new(
         config: &'a RollupConfig,
         parent_header: Sealed<Header>,
+        // TODO: @Clabby - would you rather refactor this to assume Provider implements F + H
+        // and just pass one argument?
         fetcher: F,
         hinter: H,
     ) -> Self {
diff --git a/crates/preimage/Cargo.toml b/crates/preimage/Cargo.toml
index 6f38ca5..6d549e8 100644
--- a/crates/preimage/Cargo.toml
+++ b/crates/preimage/Cargo.toml
@@ -19,7 +19,8 @@ async-trait.workspace = true
 # local
 kona-common = { path = "../common", version = "0.0.2" }
 
-serde = { version = "1.0.203", features = ["derive"], optional = true }
+# external
+rkyv = { version = "0.7.44", optional = true }
 
 [dev-dependencies]
 tokio = { version = "1.38.0", features = ["full"] }
@@ -27,4 +28,4 @@ tempfile = "3.10.1"
 
 [features]
 default = []
-serde = ["dep:serde"]
+rkyv = ["dep:rkyv"]
diff --git a/crates/preimage/src/key.rs b/crates/preimage/src/key.rs
index 99784bb..68b9934 100644
--- a/crates/preimage/src/key.rs
+++ b/crates/preimage/src/key.rs
@@ -2,13 +2,14 @@
 //! the preimage oracle.
 
 use alloy_primitives::{B256, U256};
-#[cfg(feature = "serde")]
-use serde::{Deserialize, Serialize};
+#[cfg(feature = "rkyv")]
+use rkyv::{Archive, Deserialize, Serialize};
 
 /// <https://specs.optimism.io/experimental/fault-proof/index.html#pre-image-key-types>
-#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
 #[derive(Debug, Default, Clone, Copy, Eq, PartialEq, Hash)]
 #[repr(u8)]
+#[cfg_attr(feature = "rkyv", derive(Archive, Serialize, Deserialize))]
+#[cfg_attr(feature = "rkyv", archive_attr(derive(Debug, PartialEq, Eq, PartialOrd, Ord, Hash)))]
 pub enum PreimageKeyType {
     /// Local key types are local to a given instance of a fault-proof and context dependent.
     /// Commonly these local keys are mapped to bootstrap data for the fault proof program.
@@ -56,8 +57,9 @@ impl TryFrom<u8> for PreimageKeyType {
 /// |---------|-------------|
 /// | [0, 1)  | Type byte   |
 /// | [1, 32) | Data        |
-#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
 #[derive(Debug, Default, Clone, Copy, Eq, PartialEq, Hash)]
+#[cfg_attr(feature = "rkyv", derive(Archive, Serialize, Deserialize))]
+#[cfg_attr(feature = "rkyv", archive_attr(derive(Debug, PartialEq, Eq, PartialOrd, Ord, Hash)))]
 pub struct PreimageKey {
     data: [u8; 31],
     key_type: PreimageKeyType,
diff --git a/crates/preimage/src/lib.rs b/crates/preimage/src/lib.rs
index 61906eb..d3db482 100644
--- a/crates/preimage/src/lib.rs
+++ b/crates/preimage/src/lib.rs
@@ -19,4 +19,6 @@ mod pipe;
 pub use pipe::PipeHandle;
 
 mod traits;
-pub use traits::{HintReaderServer, HintWriterClient, PreimageOracleClient, PreimageOracleServer};
+pub use traits::{
+    CommsClient, HintReaderServer, HintWriterClient, PreimageOracleClient, PreimageOracleServer,
+};
diff --git a/crates/preimage/src/traits.rs b/crates/preimage/src/traits.rs
index c62d1c5..050d6c0 100644
--- a/crates/preimage/src/traits.rs
+++ b/crates/preimage/src/traits.rs
@@ -38,6 +38,12 @@ pub trait HintWriterClient {
     async fn write(&self, hint: &str) -> Result<()>;
 }
 
+/// A [CommsClient] is a trait that combines the [PreimageOracleClient] and [HintWriterClient]
+pub trait CommsClient: PreimageOracleClient + Clone + HintWriterClient {}
+
+// Implement the super trait for any type that satisfies the bounds
+impl<T: PreimageOracleClient + Clone + HintWriterClient> CommsClient for T {}
+
 /// A [PreimageOracleServer] is a high-level interface to accept read requests from the client and
 /// write the preimage data to the client pipe.
 #[async_trait]
diff --git a/crates/primitives/Cargo.toml b/crates/primitives/Cargo.toml
index 020abdb..1bbaaa7 100644
--- a/crates/primitives/Cargo.toml
+++ b/crates/primitives/Cargo.toml
@@ -17,7 +17,7 @@ alloy-eips.workspace = true
 op-alloy-consensus.workspace = true
 
 # Superchain Registry
-superchain-primitives = { version = "0.1.1", default-features = false }
+superchain-primitives = { version = "0.1", default-features = false }
 
 # Alloy Types
 alloy-sol-types = { version = "0.7.6", default-features = false }
diff --git a/examples/trusted-sync/Cargo.toml b/examples/trusted-sync/Cargo.toml
index 8397552..4d11b4d 100644
--- a/examples/trusted-sync/Cargo.toml
+++ b/examples/trusted-sync/Cargo.toml
@@ -14,16 +14,12 @@ homepage.workspace = true
 anyhow.workspace = true
 tracing.workspace = true
 alloy-primitives = { workspace = true, features = ["serde"] }
-kona-derive = { path = "../../crates/derive", version = "0.0.2", features = ["serde", "k256", "online", "metrics"] }
+kona-derive = { path = "../../crates/derive", version = "0.0.2", features = ["serde", "k256", "online"] }
 
 # Custom dependencies
-lazy_static = "1.5.0"
-tracing-loki = "0.2.5"
 reqwest = "0.12"
-actix-web = "4.8.0"
-prometheus = { version = "0.13.4", features = ["process"] }
 tokio = { version = "1.37.0", features = ["full"] }
-tracing-subscriber = { version = "0.3.18", features = ["fmt"] }
+tracing-subscriber = "0.3.18"
 clap = { version = "4.5.4", features = ["derive", "env"] }
 serde = { version = "1.0.198", features = ["derive"] }
 alloy-provider = { version = "0.1", default-features = false }
diff --git a/examples/trusted-sync/Dockerfile b/examples/trusted-sync/Dockerfile
deleted file mode 100644
index 841837d..0000000
--- a/examples/trusted-sync/Dockerfile
+++ /dev/null
@@ -1,19 +0,0 @@
-FROM rust:latest as build
-
-RUN rustup target add x86_64-unknown-linux-musl
-RUN apt-get update && apt-get install -y musl-tools
-
-COPY ./crates/ /kona/crates
-COPY ./bin/ /kona/bin
-COPY ./examples/ /kona/examples
-COPY ./Cargo.toml /kona
-COPY ./Cargo.lock /kona
-COPY ./rustfmt.toml /kona
-COPY ./README.md /kona
-WORKDIR /kona
-
-RUN cargo build --release --config net.git-fetch-with-cli=true -p trusted-sync
-RUN cp /kona/target/release/trusted-sync /usr/local/bin/trusted-sync
-RUN chmod +x ./examples/trusted-sync/run.sh
-
-CMD ["./examples/trusted-sync/run.sh"]
diff --git a/examples/trusted-sync/run.sh b/examples/trusted-sync/run.sh
deleted file mode 100644
index 7ae8213..0000000
--- a/examples/trusted-sync/run.sh
+++ /dev/null
@@ -1,12 +0,0 @@
-#!/usr/bin/bash
-
-/usr/local/bin/trusted-sync \
-  --l1-rpc-url $L1_RPC_URL \
-  --l2-rpc-url $L2_RPC_URL \
-  --beacon-url $BEACON_URL \
-  --start-l2-block $START_L2_BLOCK \
-  --metrics-server-addr $METRICS_SERVER_ADDR \
-  --metrics-server-port $METRICS_SERVER_PORT \
-  --loki-server-addr $LOKI_SERVER_ADDR \
-  --loki-server-port $LOKI_SERVER_PORT \
-  -vvv
diff --git a/examples/trusted-sync/src/cli.rs b/examples/trusted-sync/src/cli.rs
index 597e660..41a9407 100644
--- a/examples/trusted-sync/src/cli.rs
+++ b/examples/trusted-sync/src/cli.rs
@@ -1,16 +1,6 @@
 //! This module contains all CLI-specific code.
 
-use anyhow::{anyhow, Result};
 use clap::{ArgAction, Parser};
-use reqwest::Url;
-
-const L1_RPC_URL: &str = "L1_RPC_URL";
-const L2_RPC_URL: &str = "L2_RPC_URL";
-const BEACON_URL: &str = "BEACON_URL";
-const DEFAULT_METRICS_SERVER_ADDR: &str = "127.0.0.1";
-const DEFAULT_METRICS_SERVER_PORT: u16 = 9000;
-const DEFAULT_LOKI_SERVER_ADDR: &str = "127.0.0.1";
-const DEFAULT_LOKI_SERVER_PORT: u16 = 3133;
 
 /// The host binary CLI application arguments.
 #[derive(Parser, Clone, serde::Serialize, serde::Deserialize)]
@@ -30,64 +20,4 @@ pub struct Cli {
     /// The l2 block to start from.
     #[clap(long, short, help = "Starting l2 block, defaults to chain genesis if none specified")]
     pub start_l2_block: Option<u64>,
-    /// The address of the metrics server.
-    #[clap(long, help = "Address of the metrics server")]
-    pub metrics_server_addr: Option<String>,
-    /// The metrics server port.
-    #[clap(long, help = "Port of the metrics server")]
-    pub metrics_server_port: Option<u16>,
-    /// The Loki Url endpoint.
-    #[clap(long, help = "Url to post Loki logs")]
-    pub loki_url: Option<String>,
-}
-
-impl Cli {
-    /// Returns the full metrics server address string.
-    pub fn metrics_server_addr(&self) -> String {
-        format!(
-            "{}:{}",
-            self.metrics_server_addr
-                .clone()
-                .unwrap_or_else(|| DEFAULT_METRICS_SERVER_ADDR.to_string()),
-            self.metrics_server_port.unwrap_or(DEFAULT_METRICS_SERVER_PORT)
-        )
-    }
-
-    /// Returns the full loki server address.
-    pub fn loki_addr(&self) -> Url {
-        if let Some(url) = self.loki_url.clone() {
-            return Url::parse(&url).expect("Failed to parse loki server address");
-        }
-        let str = format!("http://{DEFAULT_LOKI_SERVER_ADDR}:{DEFAULT_LOKI_SERVER_PORT}");
-        Url::parse(&str).expect("Failed to parse loki server address")
-    }
-
-    /// Returns the l1 rpc url from CLI or environment variable.
-    pub fn l1_rpc_url(&self) -> Result<Url> {
-        let url = if let Some(s) = self.l1_rpc_url.clone() {
-            s
-        } else {
-            std::env::var(L1_RPC_URL).map_err(|e| anyhow!(e))?
-        };
-        Url::parse(&url).map_err(|e| anyhow!(e))
-    }
-
-    /// Returns the l2 rpc url from CLI or environment variable.
-    pub fn l2_rpc_url(&self) -> Result<Url> {
-        let url = if let Some(s) = self.l2_rpc_url.clone() {
-            s
-        } else {
-            std::env::var(L2_RPC_URL).map_err(|e| anyhow!(e))?
-        };
-        Url::parse(&url).map_err(|e| anyhow!(e))
-    }
-
-    /// Returns the beacon url from CLI or environment variable.
-    pub fn beacon_url(&self) -> Result<String> {
-        Ok(if let Some(s) = self.beacon_url.clone() {
-            s
-        } else {
-            std::env::var(BEACON_URL).map_err(|e| anyhow!(e))?
-        })
-    }
 }
diff --git a/examples/trusted-sync/src/main.rs b/examples/trusted-sync/src/main.rs
index b6d9a47..41d7e78 100644
--- a/examples/trusted-sync/src/main.rs
+++ b/examples/trusted-sync/src/main.rs
@@ -1,44 +1,45 @@
-use anyhow::Result;
+use anyhow::{anyhow, Result};
 use clap::Parser;
 use kona_derive::online::*;
+use reqwest::Url;
 use std::sync::Arc;
-use tracing::{debug, error, info};
+use tracing::{debug, error, info, warn, Level};
 
 mod cli;
-mod metrics;
-mod telemetry;
 mod validation;
 
+// Environment Variables
+const L1_RPC_URL: &str = "L1_RPC_URL";
+const L2_RPC_URL: &str = "L2_RPC_URL";
+const BEACON_URL: &str = "BEACON_URL";
+
 const LOG_TARGET: &str = "trusted-sync";
 
-#[actix_web::main]
+#[tokio::main]
 async fn main() -> Result<()> {
-    let cfg = cli::Cli::parse();
-    let loki_addr = cfg.loki_addr();
-    telemetry::init(cfg.v, loki_addr).await?;
-    let addr = cfg.metrics_server_addr();
-    let handle = tokio::spawn(async { sync(cfg).await });
-    tokio::select! {
-        res = metrics::serve_metrics(&addr) => {
-            error!(target: LOG_TARGET, "Metrics server failed: {:?}", res);
-            return res.map_err(|e| anyhow::anyhow!(e));
-        }
-        val = handle => {
-            error!(target: LOG_TARGET, "Sync failed: {:?}", val);
-            anyhow::bail!("Sync failed: {:?}", val);
-        }
-    }
+    let cfg = crate::cli::Cli::parse();
+    init_tracing_subscriber(cfg.v)?;
+    sync(cfg).await
 }
 
-async fn sync(cli: cli::Cli) -> Result<()> {
-    // Parse CLI arguments.
-    let l1_rpc_url = cli.l1_rpc_url()?;
-    let l2_rpc_url = cli.l2_rpc_url()?;
-    let beacon_url = cli.beacon_url()?;
+async fn sync(cli_cfg: crate::cli::Cli) -> Result<()> {
+    // Parse the CLI arguments and environment variables.
+    let l1_rpc_url: Url = cli_cfg
+        .l1_rpc_url
+        .unwrap_or_else(|| std::env::var(L1_RPC_URL).unwrap())
+        .parse()
+        .expect("valid l1 rpc url");
+    let l2_rpc_url: Url = cli_cfg
+        .l2_rpc_url
+        .unwrap_or_else(|| std::env::var(L2_RPC_URL).unwrap())
+        .parse()
+        .expect("valid l2 rpc url");
+    let beacon_url: String =
+        cli_cfg.beacon_url.unwrap_or_else(|| std::env::var(BEACON_URL).unwrap());
 
     // Query for the L2 Chain ID
     let mut l2_provider =
-        AlloyL2ChainProvider::new_http(l2_rpc_url.clone(), Arc::new(Default::default()));
+        AlloyL2ChainProvider::new_http(l2_rpc_url.clone(), Arc::new(RollupConfig::default()));
     let l2_chain_id =
         l2_provider.chain_id().await.expect("Failed to fetch chain ID from L2 provider");
     let cfg = RollupConfig::from_l2_chain_id(l2_chain_id)
@@ -47,7 +48,7 @@ async fn sync(cli: cli::Cli) -> Result<()> {
 
     // Construct the pipeline
     let mut l1_provider = AlloyChainProvider::new_http(l1_rpc_url);
-    let start = cli.start_l2_block.unwrap_or(cfg.genesis.l2.number);
+    let start = cli_cfg.start_l2_block.unwrap_or(cfg.genesis.l2.number);
     let mut l2_provider = AlloyL2ChainProvider::new_http(l2_rpc_url.clone(), cfg.clone());
     let attributes =
         StatefulAttributesBuilder::new(cfg.clone(), l2_provider.clone(), l1_provider.clone());
@@ -59,7 +60,6 @@ async fn sync(cli: cli::Cli) -> Result<()> {
         .l2_block_info_by_number(start)
         .await
         .expect("Failed to fetch genesis L2 block info for pipeline cursor");
-    metrics::SAFE_L2_HEAD.inc_by(cursor.block_info.number);
     let tip = l1_provider
         .block_info_by_number(cursor.l1_origin.number)
         .await
@@ -67,79 +67,51 @@ async fn sync(cli: cli::Cli) -> Result<()> {
     let validator = validation::OnlineValidator::new_http(l2_rpc_url.clone(), &cfg);
     let mut pipeline =
         new_online_pipeline(cfg, l1_provider, dap, l2_provider.clone(), attributes, tip);
+    let mut derived_attributes_count = 0;
 
     // Continuously step on the pipeline and validate payloads.
-    let mut advance_cursor_flag = false;
     loop {
-        info!(target: LOG_TARGET, "Validated payload attributes number {}", metrics::DERIVED_ATTRIBUTES_COUNT.get());
+        info!(target: LOG_TARGET, "Validated payload attributes number {}", derived_attributes_count);
         info!(target: LOG_TARGET, "Pending l2 safe head num: {}", cursor.block_info.number);
-        if advance_cursor_flag {
-            match l2_provider.l2_block_info_by_number(cursor.block_info.number + 1).await {
-                Ok(bi) => {
-                    cursor = bi;
-                    metrics::SAFE_L2_HEAD.inc();
-                    advance_cursor_flag = false;
-                }
-                Err(e) => {
-                    error!(target: LOG_TARGET, "Failed to fetch next pending l2 safe head: {}, err: {:?}", cursor.block_info.number + 1, e);
-                    // We don't need to step on the pipeline if we failed to fetch the next pending
-                    // l2 safe head.
-                    continue;
-                }
-            }
-        }
         match pipeline.step(cursor).await {
-            Ok(_) => {
-                metrics::PIPELINE_STEPS.with_label_values(&["success"]).inc();
-                info!(target: "loop", "Stepped derivation pipeline");
-            }
-            Err(e) => {
-                metrics::PIPELINE_STEPS.with_label_values(&["failure"]).inc();
-                debug!(target: "loop", "Error stepping derivation pipeline: {:?}", e);
-            }
+            Ok(_) => info!(target: "loop", "Stepped derivation pipeline"),
+            Err(e) => warn!(target: "loop", "Error stepping derivation pipeline: {:?}", e),
         }
 
-        // Peek at the next prepared attributes and validate them.
-        if let Some(attributes) = pipeline.peek() {
-            match validator.validate(attributes).await {
-                Ok(true) => {
-                    info!(target: LOG_TARGET, "Validated payload attributes");
-                }
-                Ok(false) => {
-                    error!(target: LOG_TARGET, "Failed payload validation: {}", attributes.parent.block_info.hash);
-                    metrics::FAILED_PAYLOAD_DERIVATION.inc();
-                    let _ = pipeline.next(); // Take the attributes and continue
-                    continue;
-                }
+        if let Some(attributes) = pipeline.next_attributes() {
+            if !validator.validate(&attributes).await {
+                error!(target: LOG_TARGET, "Failed payload validation: {}", attributes.parent.block_info.hash);
+                return Ok(());
+            }
+            derived_attributes_count += 1;
+            match l2_provider.l2_block_info_by_number(cursor.block_info.number + 1).await {
+                Ok(bi) => cursor = bi,
                 Err(e) => {
-                    error!(target: LOG_TARGET, "Failed to validate payload attributes: {:?}", e);
-                    // Don't take the next attributes, re-try the current one.
-                    continue;
+                    error!(target: LOG_TARGET, "Failed to fetch next pending l2 safe head: {}, err: {:?}", cursor.block_info.number + 1, e);
                 }
             }
+            println!(
+                "Validated Payload Attributes {derived_attributes_count} [L2 Block Num: {}] [L2 Timestamp: {}] [L1 Origin Block Num: {}]",
+                attributes.parent.block_info.number + 1,
+                attributes.attributes.timestamp,
+                pipeline.origin().unwrap().number,
+            );
+            info!(target: LOG_TARGET, "attributes: {:#?}", attributes);
         } else {
             debug!(target: LOG_TARGET, "No attributes to validate");
-            continue;
-        };
-
-        // Take the next attributes from the pipeline since they're valid.
-        let attributes = if let Some(attributes) = pipeline.next() {
-            attributes
-        } else {
-            error!(target: LOG_TARGET, "Must have valid attributes");
-            continue;
-        };
-
-        // If we validated payload attributes, we should advance the cursor.
-        advance_cursor_flag = true;
-        metrics::DERIVED_ATTRIBUTES_COUNT.inc();
-        println!(
-            "Validated Payload Attributes {} [L2 Block Num: {}] [L2 Timestamp: {}] [L1 Origin Block Num: {}]",
-            metrics::DERIVED_ATTRIBUTES_COUNT.get(),
-            attributes.parent.block_info.number + 1,
-            attributes.attributes.timestamp,
-            pipeline.origin().unwrap().number,
-        );
-        debug!(target: LOG_TARGET, "attributes: {:#?}", attributes);
+        }
     }
 }
+
+fn init_tracing_subscriber(v: u8) -> Result<()> {
+    let subscriber = tracing_subscriber::fmt()
+        .with_max_level(match v {
+            0 => Level::ERROR,
+            1 => Level::WARN,
+            2 => Level::INFO,
+            3 => Level::DEBUG,
+            _ => Level::TRACE,
+        })
+        .finish();
+    tracing::subscriber::set_global_default(subscriber).map_err(|e| anyhow!(e))
+}
diff --git a/examples/trusted-sync/src/metrics.rs b/examples/trusted-sync/src/metrics.rs
deleted file mode 100644
index 995f847..0000000
--- a/examples/trusted-sync/src/metrics.rs
+++ /dev/null
@@ -1,61 +0,0 @@
-//! Metrics for the trusted sync example.
-
-use actix_web::{get, App, HttpServer, Responder};
-use anyhow::Result;
-use prometheus::{self, opts, Encoder, GaugeVec, IntCounter, TextEncoder};
-
-use lazy_static::lazy_static;
-use prometheus::{register_gauge_vec, register_int_counter};
-
-lazy_static! {
-    /// Tracks the number of failed payload derivations.
-    pub static ref FAILED_PAYLOAD_DERIVATION: IntCounter =
-        register_int_counter!("failed_payload_derivation", "Number of failed payload derivations")
-            .expect("Failed to register failed payload derivation metric");
-
-    /// Tracks the number of total payload attributes derived.
-    pub static ref DERIVED_ATTRIBUTES_COUNT: IntCounter = register_int_counter!(
-        "derived_attributes_count",
-        "Number of total payload attributes derived"
-    )
-    .expect("Failed to register derived attributes count metric");
-
-    /// Tracks the pending L2 safe head.
-    pub static ref SAFE_L2_HEAD: IntCounter =
-        register_int_counter!("safe_l2_head", "Pending L2 safe head").expect("Failed to register safe L2 head metric");
-
-    /// Tracks the number of pipeline steps.
-    pub static ref PIPELINE_STEPS: GaugeVec = {
-        let opts = opts!("trusted_sync_pipeline_steps", "Number of pipeline steps");
-        register_gauge_vec!(opts, &["status"]).expect("Failed to register pipeline steps metric")
-    };
-}
-
-/// Starts the metrics server.
-pub async fn serve_metrics(bind: &str) -> Result<()> {
-    let _ = HttpServer::new(|| App::new().service(index).service(metrics))
-        .bind(bind)
-        .map_err(|e| anyhow::anyhow!(e))?
-        .run()
-        .await;
-    Ok(())
-}
-
-#[get("/")]
-async fn index() -> impl Responder {
-    "trusted-sync-metrics-server: visit /metrics to view metrics"
-}
-
-#[get("/metrics")]
-async fn metrics() -> impl Responder {
-    let encoder = TextEncoder::new();
-    let mut buffer = vec![];
-    if let Err(e) = encoder.encode(&prometheus::gather(), &mut buffer) {
-        tracing::error!("Failed to encode prometheus metrics: {:?}", e);
-    }
-
-    let response = String::from_utf8(buffer.clone()).expect("Failed to convert bytes to string");
-    buffer.clear();
-
-    response
-}
diff --git a/examples/trusted-sync/src/telemetry.rs b/examples/trusted-sync/src/telemetry.rs
deleted file mode 100644
index 8613f7f..0000000
--- a/examples/trusted-sync/src/telemetry.rs
+++ /dev/null
@@ -1,28 +0,0 @@
-use anyhow::{anyhow, Result};
-use reqwest::Url;
-use tracing::Level;
-use tracing_subscriber::{layer::SubscriberExt, prelude::*};
-
-pub async fn init(v: u8, addr: Url) -> Result<()> {
-    let (loki_layer, task) = tracing_loki::builder()
-        .label("environment", "production")
-        .map_err(|e| anyhow!(e))?
-        .extra_field("pid", format!("{}", std::process::id()))
-        .map_err(|e| anyhow!(e))?
-        .build_url(addr)
-        .map_err(|e| anyhow!(e))?;
-
-    let std_layer = tracing_subscriber::fmt::Layer::default().with_writer(
-        std::io::stdout.with_max_level(match v {
-            0 => Level::ERROR,
-            1 => Level::WARN,
-            2 => Level::INFO,
-            3 => Level::DEBUG,
-            _ => Level::TRACE,
-        }),
-    );
-    let subscriber = tracing_subscriber::registry().with(loki_layer).with(std_layer);
-    tracing::subscriber::set_global_default(subscriber).map_err(|e| anyhow!(e))?;
-    tokio::spawn(task);
-    Ok(())
-}
diff --git a/examples/trusted-sync/src/validation.rs b/examples/trusted-sync/src/validation.rs
index af0d706..d714841 100644
--- a/examples/trusted-sync/src/validation.rs
+++ b/examples/trusted-sync/src/validation.rs
@@ -8,7 +8,7 @@ use kona_derive::types::{
     L2AttributesWithParent, L2PayloadAttributes, RawTransaction, RollupConfig,
 };
 use std::vec::Vec;
-use tracing::{error, warn};
+use tracing::warn;
 
 /// OnlineValidator
 ///
@@ -57,7 +57,7 @@ impl OnlineValidator {
             if let Ok(tx) = tx {
                 txs.push(tx);
             } else {
-                warn!(target: "validation", "Failed to fetch transaction: {:?}", tx);
+                warn!("Failed to fetch transaction: {:?}", tx);
             }
         }
         Ok((block.header, txs))
@@ -80,15 +80,10 @@ impl OnlineValidator {
     }
 
     /// Validates the given [`L2AttributesWithParent`].
-    pub async fn validate(&self, attributes: &L2AttributesWithParent) -> Result<bool> {
+    pub async fn validate(&self, attributes: &L2AttributesWithParent) -> bool {
         let expected = attributes.parent.block_info.number + 1;
         let tag = BlockNumberOrTag::from(expected);
-        match self.get_payload(tag).await {
-            Ok(payload) => Ok(attributes.attributes == payload),
-            Err(e) => {
-                error!(target: "validation", "Failed to fetch payload for block {}: {:?}", expected, e);
-                Err(e)
-            }
-        }
+        let payload = self.get_payload(tag).await.unwrap();
+        attributes.attributes == payload
     }
 }
diff --git a/justfile b/justfile
index 54b11e7..d1ddb5d 100644
--- a/justfile
+++ b/justfile
@@ -5,8 +5,6 @@ alias l := lint
 alias ln := lint-native
 alias fmt := fmt-native-fix
 alias b := build
-alias d := docker-build-ts
-alias r := docker-run-ts
 
 # default recipe to display help information
 default:
@@ -88,20 +86,3 @@ build-asterisc *args='':
     -v `pwd`/:/workdir \
     -w="/workdir" \
     ghcr.io/ethereum-optimism/kona/asterisc-builder:main cargo build --workspace --all -Zbuild-std $@ --exclude kona-host --exclude trusted-sync
-
-# Build the `trusted-sync` docker image
-docker-build-ts *args='':
-  docker build -t trusted-sync -f examples/trusted-sync/Dockerfile . $@
-
-# Run the `trusted-sync` docker container
-docker-run-ts:
-  docker run -it \
-    -e L1_RPC_URL=$L1_RPC_URL \
-    -e L2_RPC_URL=$L2_RPC_URL \
-    -e BEACON_URL=$BEACON_URL \
-    -e START_L2_BLOCK=$START_L2_BLOCK \
-    -e METRICS_SERVER_ADDR=$METRICS_SERVER_ADDR \
-    -e METRICS_SERVER_PORT=$METRICS_SERVER_PORT \
-    -e LOKI_SERVER_ADDR=$LOKI_SERVER_ADDR \
-    -e LOKI_SERVER_PORT=$LOKI_SERVER_PORT \
-    trusted-sync
